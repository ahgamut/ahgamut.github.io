<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine-learning on Blog Needs a Name</title><link>https://ahgamut.github.io/categories/machine-learning/</link><description>Recent content in machine-learning on Blog Needs a Name</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 24 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://ahgamut.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Debugging C With Cosmopolitan Libc</title><link>https://ahgamut.github.io/2022/10/23/debugging-c-with-cosmo/</link><pubDate>Sun, 23 Oct 2022 00:00:00 +0000</pubDate><guid>https://ahgamut.github.io/2022/10/23/debugging-c-with-cosmo/</guid><description>&lt;p>&lt;a href="https://justine.lol/cosmopolitan">Cosmopolitan Libc&lt;/a> provides a suite of debugging features that enhance
the C development experience: function call tracing, &lt;code>gdb&lt;/code> integration, an
ASAN/UBSAN runtime, and more! A lot of fast and critical code is written in C &amp;ndash;
If you&amp;rsquo;re using software written in C, interfacing with C libraries, fixing bugs
in C code, or even rewriting C software in some other language, it helps to
understand what your C code is doing. Debugging isn&amp;rsquo;t just a diaspora of
&lt;code>printf&lt;/code> statements &amp;ndash; in this blog post, we&amp;rsquo;ll look at how Cosmopolitan Libc
helps with debugging C, true and properly, using this &lt;a href="https://github.com/ahgamut/debug-cosmo-example">example repo&lt;/a>.&lt;/p>
&lt;h2 id="an-example-program">An example program&lt;/h2>
&lt;p>Consider &lt;a href="https://github.com/ahgamut/debug-cosmo-example/blob/main/hex16.c">&lt;code>hex16.c&lt;/code>&lt;/a>: the user specifies a file at the command
line, the program opens the file, prints (up to) the first 16 bytes as
hexadecimal values, and then prints the bytes read as an ASCII string. You can
find the entire code &lt;a href="https://github.com/ahgamut/debug-cosmo-example">here&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;stdio.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;span class="cp">#define NUM_CHARS 16
&lt;/span>&lt;span class="cp">&lt;/span>
&lt;span class="kt">void&lt;/span> &lt;span class="nf">hex16&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">const&lt;/span> &lt;span class="kt">char&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">filename&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="n">FILE&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">fp&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fopen&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filename&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;r&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="kt">char&lt;/span> &lt;span class="n">res&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">NUM_CHARS&lt;/span>&lt;span class="p">];&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;hex16.c -- reading file %s&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">filename&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">NUM_CHARS&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="o">++&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="n">c&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fgetc&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fp&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">feof&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fp&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">break&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;0x%02x &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="n">res&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="kt">char&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="n">res&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="sc">&amp;#39;\0&amp;#39;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="n">fclose&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fp&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">%s&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">res&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">argc&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">char&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">argv&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="n">hex16&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">argv&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]);&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let&amp;rsquo;s build the above program with &lt;code>make&lt;/code> and test it on a sample file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">make hex16.com
./hex16.com ./sample1.txt
&lt;span class="c1"># hex16.c -- reading file ./sample1.txt&lt;/span>
&lt;span class="c1"># 0x63 0x6f 0x73 0x6d 0x6f 0x20 0x6c 0x69 0x62 0x63 0x0a &lt;/span>
&lt;span class="c1"># cosmo libc&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But what happens if you don&amp;rsquo;t provide a file or provide a nonexistent file?&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">./hex16.com
&lt;span class="c1"># Segmentation fault&lt;/span>
./hex16.com ./missing.txt
&lt;span class="c1"># Segmentation fault&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Hmm, &lt;code>Segmentation fault&lt;/code> is not quite informative &amp;ndash; some part of the program
is causing a crash, but where?&lt;/p>
&lt;h2 id="gdb-and-backtraces">&lt;code>gdb&lt;/code> and backtraces&lt;/h2>
&lt;p>With Cosmopolitan Libc, you can have &lt;a href="https://www.sourceware.org/gdb/">&lt;code>gdb&lt;/code>&lt;/a> integration and detailed
backtraces for your C program in just one line: add &lt;code>ShowCrashReports();&lt;/code> at the
start of the &lt;code>main&lt;/code> function. Let&amp;rsquo;s build &lt;a href="https://github.com/ahgamut/debug-cosmo-example/blob/main/hex16-backtrace.c">&lt;code>hex16-backtrace.c&lt;/code>&lt;/a>
which is just that:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">make hex16-backtrace.com
&lt;span class="c1"># try with no arguments&lt;/span>
./hex16-backtrace.com
&lt;span class="c1"># or try with a nonexistent file&lt;/span>
./hex16-backtrace.com ./missing.txt
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now if you have &lt;a href="https://www.sourceware.org/gdb/">&lt;code>gdb&lt;/code>&lt;/a> available on &lt;code>$PATH&lt;/code>, you would get a TUI (terminal
user interace) showing the register contents and the backtrace of the crash,
like the image below:&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/debug-cosmo/gdb-cosmo.png" alt="a gdb tui showing register info and the location of the crash">&lt;/p>
&lt;p>Type &lt;code>bt&lt;/code> and press &lt;code>Enter&lt;/code> to view the backtrace in &lt;code>gdb&lt;/code>, and exit by pressing
&lt;code>Ctrl+D&lt;/code>. You can set up a config for &lt;code>gdb&lt;/code> from the Cosmopolitan Libc README
&lt;a href="https://github.com/jart/cosmopolitan#gdb">here&lt;/a>.&lt;/p>
&lt;p>If &lt;code>gdb&lt;/code> is not available, or if you&amp;rsquo;re running the program as part of a test
script, you would get the backtrace in text, showing the register contents and
the backtrace of the crash:&lt;/p>
&lt;pre tabindex="0">&lt;code>error: Uncaught SIGSEGV (SEGV_MAPERR) on X550LD pid 256891 tid 256891
./hex16-backtrace.com
EUNKNOWN/0/No error information
Linux #1 SMP Debian 5.10.106-1 (2022-03-17) X550LD 5.10.0-13-amd64
RAX 0000000000000000 RBX 00007ffe5c5c9a70 RDI 000000000042dd48 ST(0) 0.0
RCX 0000000000000000 RDX 0000000000000000 RSI 0000000000000240 ST(1) 0.0
RBP 00007000007fff80 RSP 00007000007fff60 RIP 000000000040b698 ST(2) 0.0
R8 0000000000000000 R9 0000000000000001 R10 0000000000000004 ST(3) 0.0
R11 0000000000000293 R12 0000000000000000 R13 000000000042dd46 ST(4) 0.0
R14 00007ffe5c5c9a80 R15 00007ffe5c5c9b90 VF PF ZF IF
XMM0 00000000000000000000000000000000 XMM8 00000000000000000000000000000000
XMM1 7865682f656c706d6178652d6f6d736f XMM9 00000000000000000000000000000000
XMM2 632d67756265642f6f6d736f632f6666 XMM10 00000000000000000000000000000000
XMM3 7574732f6d6168747561672f656d6f68 XMM11 00000000000000000000000000000000
XMM4 6f632e65636172746b6361622d363178 XMM12 00000000000000000000000000000000
XMM5 65682f656c706d6178652d6f6d736f63 XMM13 00000000000000000000000000000000
XMM6 2d67756265642f6f6d736f632f666675 XMM14 00000000000000000000000000000000
XMM7 74732f6d6168747561672f656d6f682f XMM15 00000000000000000000000000000000
0x000000000040b697: fixpathname at /home/jart/cosmo/libc/stdio/fopen.c:26
(inlined by) fopen at /home/jart/cosmo/libc/stdio/fopen.c:62
0x00000000004098d0: hex16 at /home/gautham/stuff/cosmo/debug-cosmo-example/hex16-backtrace.c:5
0x000000000040291e: main at /home/gautham/stuff/cosmo/debug-cosmo-example/hex16-backtrace.c:22
0x00000000004029cb: cosmo at /home/jart/cosmo/libc/runtime/cosmo.S:77
0x0000000000402503: _start at /home/jart/cosmo/libc/crt/crt.S:103
10008004-10008004 rw-pa- 1x automap 64kB w/ 7872kB hole
10008080-100080ff rw-pa- 128x automap 8192kB w/ 96tB hole
6fe00004-6fe00004 rw-paF 1x g_fds 64kB
70000000-7000007f rw-Sa- 128x stack 8192kB
# 16mB total mapped memory
./hex16-backtrace.com
&lt;/code>&lt;/pre>&lt;p>From the backtrace, you now know that not providing a file causes a crash
involving &lt;code>fopen&lt;/code>, and so update the program to check if the first parameter of
&lt;code>fopen&lt;/code> (ie &lt;code>argv[1]&lt;/code>) is NULL or not. Note that backtrace generation depends on
the &lt;code>hex16-backtrace.com.dbg&lt;/code> file being located in the same directory as
&lt;code>hex16-backtrace.com&lt;/code>, as it contains necessary debugging information.&lt;/p>
&lt;p>Just knowing the backtrace of a crash helps reduce the time needed to fix an
error: when porting &lt;a href="https://github.com/jart/cosmopolitan/pull/305">&lt;code>make&lt;/code> to Cosmopolitan Libc&lt;/a>, adding a
&lt;code>ShowCrashReports&lt;/code> showed that &lt;code>make&lt;/code> had some large &lt;code>alloca&lt;/code> calls which were
causing a crash. The fix was to add a &lt;code>STATIC_STACK_SIZE&lt;/code> call in the &lt;code>main&lt;/code>
function, and then &lt;code>make&lt;/code> could build the entire Cosmopolitan Libc monorepo.&lt;/p>
&lt;h2 id="function-call-tracing-with---ftrace">function call tracing with &lt;code>--ftrace&lt;/code>&lt;/h2>
&lt;p>Sometimes a backtrace of the crash alone is not sufficient. Cosmopolitan Libc
allows you to log &lt;em>every function call&lt;/em> over the program&amp;rsquo;s execution &amp;ndash; just
pass &lt;a href="https://justine.lol/ftrace/">&lt;code>--ftrace&lt;/code>&lt;/a> at the end of your program, like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">./hex16.com ./missing.txt --ftrace
&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code># truncated example
FUN 257012 1'567'864 48 &amp;amp;main
FUN 257012 1'573'031 112 &amp;amp;hex16
FUN 257012 1'578'356 160 &amp;amp;fopen
FUN 257012 1'612'346 336 &amp;amp;printf
FUN 257012 1'720'829 144 &amp;amp;fgetc
FUN 257012 1'726'479 176 &amp;amp;fgetc_unlocked
Segmentation Fault
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>The first column indicates it is a function call&lt;/li>
&lt;li>the second column shows the process ID/thread ID calling the function&lt;/li>
&lt;li>the third column shows the approximate timestamp from the start of program
execution&lt;/li>
&lt;li>the last column shows the name of the function that was called.&lt;/li>
&lt;/ul>
&lt;p>The &lt;code>ftrace&lt;/code> output gets printed to &lt;code>stderr&lt;/code> by default; it is useful to
redirect it to a file for later analysis. &lt;code>ftrace&lt;/code> does not require
&lt;code>ShowCrashReports()&lt;/code> at the start of the &lt;code>main&lt;/code> function, though it still
requires the &lt;code>hex16.com.dbg&lt;/code> for &lt;code>hex16.com&lt;/code>. You can read more about how &lt;code>ftrace&lt;/code>
works &lt;a href="https://justine.lol/ftrace/">here&lt;/a>.&lt;/p>
&lt;p>&lt;code>ftrace&lt;/code> also provides insight into program performance. I wrote a &lt;a href="https://github.com/jart/cosmopolitan/pull/285">Python
wrapper for &lt;code>ftrace&lt;/code>&lt;/a> so I could examine how the CPython3.6 runtime
behaves. For example, here&amp;rsquo;s how many calls it takes to add two values in
Python3.6 built with Cosmopolitan Libc:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="kn">import&lt;/span> &lt;span class="nn">cosmo&lt;/span>
&lt;span class="n">a&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;span class="k">with&lt;/span> &lt;span class="n">cosmo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ftrace&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="n">c&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">a&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">b&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code>&amp;amp;meth_dealloc
&amp;amp;PyFrame_BlockSetup 76
&amp;amp;object_dealloc 265
&amp;amp;PyObject_Free 82
&amp;amp;_PyObject_Free.isra.0 52
&amp;amp;PyDict_GetItem 333
&amp;amp;lookdict_unicode_nodummy 157
&amp;amp;PyDict_GetItem 166
&amp;amp;lookdict_unicode_nodummy 34
&amp;amp;PyNumber_Add 273
&amp;amp;binary_op1 69
&amp;amp;long_add 178
&amp;amp;PyLong_FromLong 135
&amp;amp;PyDict_SetItem 273
&amp;amp;insertdict 164
&amp;amp;lookdict_unicode_nodummy 53
&amp;amp;PyFrame_BlockPop 320
&amp;amp;PyObject_CallFunctionObjArgs 249
&amp;amp;object_vacall 40
&amp;amp;_PyObject_FastCallDict 95
&amp;amp;_PyCFunction_FastCallDict 53
&amp;amp;_PyMethodDef_RawFastCallDict 86
&amp;amp;_PyStack_AsTuple 61
&amp;amp;PyTuple_New 121
&amp;amp;FtracerObject_exit 199
&lt;/code>&lt;/pre>&lt;p>The numbers on the right are an approximate measure of time each function takes,
which is pretty useful for a &amp;ldquo;slow&amp;rdquo; language like Python3.6&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. &lt;code>ftrace&lt;/code>
helped write a &lt;a href="https://github.com/jart/cosmopolitan/pull/425">custom &lt;code>sys.meta_path&lt;/code> importer&lt;/a> for Python3.6 in
Cosmopolitan Libc &amp;ndash; I just moved code from Python into C until the size of the
ftrace logs stopped decreasing.&lt;/p>
&lt;h2 id="system-call-tracing-with---strace">system call tracing with &lt;code>--strace&lt;/code>&lt;/h2>
&lt;p>Sometimes tracing function calls is too much information, and you just want to
narrow down the error region from some logging information. If your program uses
a bunch of system calls, you can log them like functions, by passing
&lt;code>--strace&lt;/code> at the end of your program invocation, like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">./hex16.com ./missing.txt --strace
&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code>SYS 257304 43'627 bell system five system call support 171 magnums loaded on gnu/systemd
SYS 257304 99'854 mmap(0x700000000000, 8'388'608, PROT_READ|PROT_WRITE, MAP_STACK|MAP_ANONYMOUS, -1, 0) → 0x700000000000 (8'388'608 bytes total)
SYS 257304 892'097 getenv(&amp;quot;TERM&amp;quot;) → &amp;quot;xterm-256color&amp;quot;
SYS 257304 908'170 openat(AT_FDCWD, &amp;quot;./missing.txt&amp;quot;, 0, 0) → -1 errno= 2
SYS 257304 932'876 write(1, u&amp;quot;hex16.c -- reading file ./missing.txt◙&amp;quot;, 38) → 38 errno= 2
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>The first column indicates it is a system call&lt;/li>
&lt;li>the second column shows the process ID/thread ID making the call&lt;/li>
&lt;li>the third column shows the approximate timestamp from the start of program
execution&lt;/li>
&lt;li>the fourth column shows output of the system call along with errno values&lt;/li>
&lt;/ul>
&lt;p>Unlike &lt;code>ShowCrashReports&lt;/code> and &lt;code>ftrace&lt;/code>, the &lt;code>--strace&lt;/code> flag does not require the
&lt;code>hex16.com.dbg&lt;/code> file to be present. Now you see that the &lt;code>openat&lt;/code> resulted in
an &lt;code>-1 errno 2&lt;/code> if the file doesn&amp;rsquo;t exist, so let&amp;rsquo;s update the code to check the
&lt;code>FILE *&lt;/code> pointer before calling &lt;code>fgetc&lt;/code>. Thus you get the fixed program
&lt;a href="https://github.com/ahgamut/debug-cosmo-example/blob/main/hex16-fixed.c">&lt;code>hex16-fixed.c&lt;/code>&lt;/a> below:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;stdio.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;span class="cp">#define NUM_CHARS 16
&lt;/span>&lt;span class="cp">&lt;/span>
&lt;span class="kt">void&lt;/span> &lt;span class="nf">hex16&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">const&lt;/span> &lt;span class="kt">char&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">filename&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="n">FILE&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">fp&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fopen&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filename&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;r&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="kt">char&lt;/span> &lt;span class="n">res&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">NUM_CHARS&lt;/span>&lt;span class="p">];&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">!&lt;/span>&lt;span class="n">fp&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;unable to read %s!&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">filename&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="k">return&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;hex16.c -- reading file %s&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">filename&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">NUM_CHARS&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="o">++&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="n">c&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fgetc&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fp&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">feof&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fp&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">break&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;0x%02x &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="n">res&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="kt">char&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="n">res&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="sc">&amp;#39;\0&amp;#39;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="n">fclose&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fp&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">%s&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">res&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="kt">int&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">argc&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">char&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">argv&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">argc&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;USAGE:&lt;/span>&lt;span class="se">\n\t&lt;/span>&lt;span class="s">%s FILENAME&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">argv&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]);&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="n">hex16&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">argv&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]);&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="asanubsan">ASAN/UBSAN&lt;/h2>
&lt;p>The two errors in &lt;code>hex16.com&lt;/code> have been fixed, so it&amp;rsquo;s time to try another
testcase to see if there are any more. What happens if the input file contains
16 or more characters?&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">./hex16.com ./sample2.txt
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>hex16.com&lt;/code> has inconsistent behavior with &lt;code>sample2.txt&lt;/code> &amp;ndash; sometimes it prints
extra garbage characters. But there is a &lt;code>res[i] = '\0'&lt;/code> after the loop to
terminate the string, so what&amp;rsquo;s going on? Let&amp;rsquo;s build with the Cosmopolitan
Libc&amp;rsquo;s ASAN/UBSAN runtime and find out:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">make clean
make &lt;span class="nv">MODE&lt;/span>&lt;span class="o">=&lt;/span>dbg hex16-backtrace.com
./hex16-backtrace.com ./sample2.txt
&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code>hex16-backtrace.c:16: ubsan error: 'int' index 16 into 'char [16]' out of bounds (tid 257624)
0x0000000000480c00: __ubsan_handle_out_of_bounds at /home/jart/cosmo/libc/intrin/ubsan.c:289
0x0000000000421658: hex16 at /home/gautham/stuff/cosmo/debug-cosmo-example/hex16-backtrace.c:16
0x0000000000402bf1: main at /home/gautham/stuff/cosmo/debug-cosmo-example/hex16-backtrace.c:22
0x0000000000402cfd: cosmo at /home/jart/cosmo/libc/runtime/cosmo.S:77
0x0000000000402543: _start at /home/jart/cosmo/libc/crt/crt.S:103
&lt;/code>&lt;/pre>&lt;p>Ah &amp;ndash; when the file has more than 16 characters, the null terminator is written
&lt;em>outside&lt;/em> the buffer, causing a buffer overflow when the string is printed. Now
you can change the buffer to have one extra character, to handle this case,
leading to the now again-fixed &lt;a href="https://github.com/ahgamut/debug-cosmo-example/blob/main/hex16-ubsan.c">&lt;code>hex16-ubsan.c&lt;/code>&lt;/a>.&lt;/p>
&lt;p>Cosmopolitan&amp;rsquo;s ASAN/UBSAN runtime adds a magical improvement to your C
development workflow&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>, for a tiny cost. Your build times increase only
marginally, you avoid any new arguments with the compiler, you still write your
tests as usual, and your binaries have almost the same performance. And of
course, your binaries will now have runtime memory safety.&lt;/p>
&lt;h2 id="in-case-of-emergency-or-lack-of-patience">In case of emergency (or lack of patience)&lt;/h2>
&lt;p>Sometimes you find an annoying bug that occurs only during a specific sequence
of events, and you just haven&amp;rsquo;t figured it out. It&amp;rsquo;s &lt;u>not related to
ASAN/UBSAN&lt;/u> &amp;ndash; the runtime tells you some memory access is invalid, which is
good to know, but you don&amp;rsquo;t know where it all started. The &lt;u>system calls are
not shining light into the issue&lt;/u>, because it isn&amp;rsquo;t related to how your
program interacts with the OS. The &lt;u>function call sequences are too many&lt;/u>,
and mixed in due to multithreading, so it&amp;rsquo;s difficult for you to make sense of
what&amp;rsquo;s going on. You &lt;u>start &lt;code>gdb&lt;/code> and setup a dozen breakpoints&lt;/u> before
running the program, but it&amp;rsquo;s too stop-start, and you don&amp;rsquo;t have enough
experience or patience to poke at the right spots. In frustration, you reach for
the good old &lt;code>printf&lt;/code> statements, but they don&amp;rsquo;t work either! You have no tools,
because your tools haven&amp;rsquo;t set up enough for your tools, like that bug where
Python hasn&amp;rsquo;t set up &lt;code>stdin&lt;/code> because the &lt;code>encodings&lt;/code> module hasn&amp;rsquo;t been
loaded&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup> or the one where Rust&amp;rsquo;s thread-local storage makes some
seemingly weird memory requests from the libc on startup&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>You&amp;rsquo;re backed into a corner. How do you debug this seemingly impervious
&lt;a href="https://en.wikipedia.org/wiki/Heisenbug">heisenbug&lt;/a>?&lt;/p>
&lt;ol>
&lt;li>
&lt;p>You imagine yourself as an &lt;code>x86_64&lt;/code> chip (complete with power supply, RAM,
and peripherals) and start &lt;a href="https://en.wikipedia.org/wiki/Rubber_duck_debugging">rubberducking&lt;/a> each assembly instruction
to hapless passerby until the end of time or until the bug is found,
whichever is earlier.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You use &lt;a href="https://justine.lol/cosmopolitan/documentation.html#kprintf">Cosmopolitan Libc&amp;rsquo;s &lt;code>kprintf&lt;/code>&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;a href="https://justine.lol/cosmopolitan/documentation.html#kprintf">&lt;code>kprintf&lt;/code>&lt;/a> is the final tool in the Cosmopolitan Libc debugging
arsenal. Look at the &lt;a href="https://github.com/jart/cosmopolitan/blob/ef9776755ee3646029624fe30de5d58a3c03f6f6/libc/intrin/kprintf.greg.c">&lt;code>kprintf&lt;/code> source code&lt;/a> &amp;ndash; It&amp;rsquo;s a lean
implementation of &lt;code>printf&lt;/code> designed to work &lt;em>everywhere&lt;/em>. It&amp;rsquo;s what Cosmopolitan
Libc uses when the other functions want to write logs, even after the program
has crashed. So it has to work at all times. This is what happens if you try to
print some weird memory location using &lt;code>kprintf&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="n">kprintf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;%s&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31415&lt;/span>&lt;span class="p">);&lt;/span>
&lt;span class="c1">//!!7ab7
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can even clone the Cosmopolitan Libc monorepo, add &lt;code>kprintf&lt;/code> calls in
Cosmopolitan Libc&amp;rsquo;s internal functions, and test your code with your own
debug-customized libc! When all else fails, &lt;code>kprintf&lt;/code> can get the job done,
provided you use it &lt;strike>judiciously&lt;/strike> to print the value of every
variable after every statement in every function that your program has to call.&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/debug-cosmo/kprintf.jpg" alt="bell curve meme with printf and kprintf">&lt;/p>
&lt;h2 id="closing-notes">Closing Notes&lt;/h2>
&lt;p>Nobody writes perfect code in one try. Many eyes make bugs scarce. With
Cosmopolitan Libc, debugging becomes a game of Scotland Yard, instead of
blind-man&amp;rsquo;s buff &amp;ndash; instead of stumbling around and stubbing your toes, you have
&lt;strong>five&lt;/strong> different angles to understand what your program is doing and determine
where it starts going off the rails:&lt;/p>
&lt;ul>
&lt;li>you can have a simple backtrace with the register contents&lt;/li>
&lt;li>you can log all (or a subset of) the function calls to see which sequence possibly
leads to a crash or a slowdown&lt;/li>
&lt;li>you can log all the system calls and examine the interaction between your
program and the OS&lt;/li>
&lt;li>you can learn to use &lt;code>gdb&lt;/code> and dissect your program with an ever-increasing number
of breakpoints or similar wizardry&lt;/li>
&lt;li>when at your wit&amp;rsquo;s end, you can revert to old habits, only this time you use
&lt;code>kprintf&lt;/code> instead of &lt;code>printf&lt;/code> and gain superpowers&lt;/li>
&lt;/ul>
&lt;p>Underneath all the libraries, syntax, abstractions, and optimizations, we still
need to have some idea of what&amp;rsquo;s going on. Writing programs is a lot more fun
when we can understand what the computer is actually doing. Detailed feedback
helps understand programs better, and quick feedback helps develop programs
faster. Cosmopolitan Libc provides a set of debugging tools we can use to
enrich our understanding of the programs we write.&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Python is undergoing a lot of performance improvements nowadays &amp;ndash; On
2022-08-05, CPython released &lt;a href="https://github.com/python/cpython/releases/tag/v3.11.0rc1">&lt;code>3.11.0rc1&lt;/code>&lt;/a>, and I ported that to
Cosmopolitan Libc &lt;a href="https://github.com/ahgamut/cpython/tree/cosmo_py311">here&lt;/a>. The 3.11 port doesn&amp;rsquo;t have &lt;code>ftrace&lt;/code>
or the other goodies yet; it&amp;rsquo;ll be interesting to see how &lt;code>ftrace&lt;/code> gives
insight into CPython&amp;rsquo;s new &amp;ldquo;JIT-like&amp;rdquo; optimization tricks.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>A beautiful thing happens after a while developing with &lt;code>MODE=dbg&lt;/code>: you&amp;rsquo;re
still as fast as before, but now you have a sixth sense, an intuition, or &lt;a href="https://books.google.com/books/about/A_Discipline_of_Programming.html?id=MsUmAAAAMAAJ">a
discipline of programming&lt;/a> in C. Because the safety of UBSAN enforces
only lenient bounds, you start writing UBSAN-tolerant code, but you also
gain the confidence to gamble with performance tricks, knowing that UBSAN
will save you if things go awry. I had never written a JSON parser before,
but I wrote one in C, with &lt;a href="https://github.com/ahgamut/cosmopolitan/tree/dabbajson/third_party/dabbajson">NaN-boxing and pointer manipulation&lt;/a>, in
a few afternoons. It passes around 90% of the &lt;a href="https://github.com/nst/JSONTestSuite">most comprehensive JSON Test
suite&lt;/a>, on &lt;code>MODE=dbg&lt;/code> too.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>This was a nasty bug that happened if you didn&amp;rsquo;t provide a proper folder
location for Python 3 to import its standard library. Here&amp;rsquo;s my limited
recall: Python 3 is Unicode-by-default. But it&amp;rsquo;s not really Unicode when it
starts up, it&amp;rsquo;s still mostly ASCII-ish. Python does some locale checking
before attempting to import &lt;code>encodings.py&lt;/code>, and then sets up almost
everything else. So if &lt;code>encodings.py&lt;/code> is not found, Python gets stuck in
this limbo and aborts. I could not connect the error messages to
&lt;code>encodings.py&lt;/code>, so I just &lt;code>kprintf&lt;/code>&amp;rsquo;d every call in the import sequence
until I found the fix.&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>Don&amp;rsquo;t &lt;code>panic!&lt;/code> I said &lt;em>seemingly&lt;/em>. There wasn&amp;rsquo;t anything weird with how Rust
initialized thread-local storage, because the Rust examples I wrote still
worked on &lt;code>glibc&lt;/code>. We eventually narrowed the bug down to a pointer
initialization in &lt;code>pthread_create&lt;/code> in Cosmopolitan Libc, and the fix was a
&lt;a href="https://github.com/jart/cosmopolitan/pull/606">single line&lt;/a>. Cosmopolitan Libc does have &lt;code>pthreads&lt;/code> support now,
and it can run multithreaded &lt;a href="https://github.com/ahgamut/cpython/blob/cosmo_py311/threading_example.py">Python 3.11 scripts&lt;/a> and &lt;a href="https://github.com/ahgamut/rust-ape-example">Rust
executables&lt;/a>.&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Actually Portable Executables with Rust and Cosmopolitan Libc</title><link>https://ahgamut.github.io/2022/07/27/ape-rust-example/</link><pubDate>Wed, 27 Jul 2022 00:00:00 +0000</pubDate><guid>https://ahgamut.github.io/2022/07/27/ape-rust-example/</guid><description>&lt;blockquote>
&lt;p>aka &amp;ldquo;Rust is Actually Portable&amp;rdquo;, after &lt;a href="https://ahgamut.github.io/2021/02/27/ape-cosmo/">Lua&lt;/a> and &lt;a href="https://ahgamut.github.io/2021/07/13/ape-python/">Python&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>I just built a &lt;a href="https://rust-lang.org">Rust&lt;/a> executable that runs on six operating systems
(Linux, Windows, MacOS, FreeBSD, NetBSD, OpenBSD). If you&amp;rsquo;d like to build it
yourself, clone &lt;a href="https://github.com/ahgamut/rust-ape-example">this repo&lt;/a> and follow the README &amp;ndash; you&amp;rsquo;ll need a recent
&lt;code>gcc&lt;/code>, &lt;code>ld.bfd&lt;/code>, &lt;code>objcopy&lt;/code>, &lt;code>bash&lt;/code>, and the latest (nightly) versions of
&lt;code>cargo&lt;/code>, &lt;code>rustc&lt;/code>, and friends.&lt;/p>
&lt;p>I&amp;rsquo;ve been recently getting into Rust, and it seems pretty cool! I&amp;rsquo;ve also gotten
a bunch of software to run on &lt;a href="https://github.com/jart/cosmopolitan">Cosmopolitan Libc&lt;/a> over the last
year&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, so in June I thought combining Rust with Cosmopolitan Libc would
be interesting. Here&amp;rsquo;s how I got to a &lt;code>hello world!&lt;/code> Actually Portable
Executable with Rust.&lt;/p>
&lt;h2 id="a-minimal-executable">A minimal executable&lt;/h2>
&lt;p>A good thing about Rust was, unlike Python or Lua, no messing around with C
headers. Just find a way to tell &lt;code>cargo&lt;/code> to link with &lt;code>cosmopolitan.a&lt;/code> at the
very end, and you get an APE. I looked up the &lt;a href="https://docs.rust-embedded.org/embedonomicon/preface.html">Rust
Embedonomicon&lt;/a> and
built a &lt;code>no_std&lt;/code> example, but it wasn&amp;rsquo;t that useful &amp;ndash; the executable just
crashed and I didn&amp;rsquo;t know if it was on purpose. But the Embedonomicon also
described how I could create a &lt;a href="https://docs.rust-embedded.org/embedonomicon/custom-target.html">custom target for
Rust&lt;/a>, based on
the available targets. Jackpot!&lt;/p>
&lt;p>I created a custom target called &lt;code>cosmo.json&lt;/code>, based on the existing
&lt;code>x86_64-linux-unknown-gnu&lt;/code> and &lt;code>x86_64-linux-unknown-musl&lt;/code>. It took some trial
and error (I set up my own &lt;code>panic&lt;/code> handler, but then it clashed with
&lt;code>panic_abort&lt;/code>, but then it didn&amp;rsquo;t when I changed the flags to cargo), but
eventually I got this simple example below to compile (I took it from some
online Rust discussion about the &lt;code>libc&lt;/code> crate, I think the code was written by
&lt;a href="https://github.com/steveklabnik">&lt;code>steveklabnik&lt;/code>&lt;/a>).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="cp">#![no_main]&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="cp">#![no_std]&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="cp">#![feature(rustc_private)]&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="k">extern&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">crate&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">libc&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="cp">#[no_mangle]&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="k">pub&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">extern&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s">&amp;#34;C&amp;#34;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">fn&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">_argc&lt;/span>: &lt;span class="kt">isize&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">_argv&lt;/span>: &lt;span class="o">*&lt;/span>&lt;span class="k">const&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="k">const&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kt">u8&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>-&amp;gt; &lt;span class="kt">isize&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">const&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">HELLO&lt;/span>: &lt;span class="kp">&amp;amp;&lt;/span>&lt;span class="o">&amp;#39;&lt;/span>&lt;span class="nb">static&lt;/span> &lt;span class="kt">str&lt;/span> &lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s">&amp;#34;Hello, world! %d + %d = %d\n\0&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">x&lt;/span>: &lt;span class="kt">i32&lt;/span> &lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">y&lt;/span>: &lt;span class="kt">i32&lt;/span> &lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">unsafe&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">libc&lt;/span>::&lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">HELLO&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">as_ptr&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="k">const&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">_&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="cp">#[panic_handler]&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="k">fn&lt;/span> &lt;span class="nf">my_panic&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">_info&lt;/span>: &lt;span class="kp">&amp;amp;&lt;/span>&lt;span class="nc">core&lt;/span>::&lt;span class="n">panic&lt;/span>::&lt;span class="n">PanicInfo&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>-&amp;gt; &lt;span class="o">!&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">loop&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{}&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once I got the &lt;code>libc&lt;/code> crate to work, I could do a lot of things. I took a bunch
of simple C programs, rewrote them in unsafe Rust with the &lt;code>libc&lt;/code> crate, and
generally checked if the build process was okay.&lt;/p>
&lt;h2 id="building-the-std-crate">Building the &lt;code>std&lt;/code> crate&lt;/h2>
&lt;p>Now I had some simple Rust APEs, but I felt that saying &amp;ldquo;Rust is Actually
Portable&amp;rdquo; and then showing a bunch of C-like programs with unsafe wouldn&amp;rsquo;t cut
it, so I went on another round of debugging to get the &lt;code>std&lt;/code> crate to build.&lt;/p>
&lt;p>The &lt;code>std&lt;/code> crate pulls in a lot of different crates! There&amp;rsquo;s &lt;code>core&lt;/code>, &lt;code>libc&lt;/code>, and
&lt;code>alloc&lt;/code>, which I used for the above example, &lt;code>panic_abort&lt;/code>, &lt;code>panic_unwind&lt;/code>,
&lt;code>backtrace&lt;/code>, and &lt;code>proc_macro&lt;/code>, and subcomponents of &lt;code>std&lt;/code> itself. I got a tour
of the code in the &lt;code>std&lt;/code> crate by writing an incomplete target &lt;code>cosmo.json&lt;/code>: I&amp;rsquo;d
change a configuration flag, some part of &lt;code>std&lt;/code> would break because my flag was
wrong, and I&amp;rsquo;d learn something new about Rust and how &lt;code>std&lt;/code> worked.&lt;/p>
&lt;p>Once I figured out the right flags in the target &lt;code>cosmo.json&lt;/code>, most of the bugs
with &lt;code>std&lt;/code> went away. The few that remained deserve special mention because it
took me a while to fix them.&lt;/p>
&lt;h2 id="weird-bugs-and-their-workarounds">Weird bugs and their workarounds&lt;/h2>
&lt;p>One of the weird bugs was internet-related code of &lt;code>std&lt;/code> which called the &lt;code>libc&lt;/code>
crate (like &lt;code>struct hostent&lt;/code> or something). I went through Cosmopolitan Libc
source code, and everything seemed fine, so the mistake was elsewhere. I
modified the &lt;code>std&lt;/code> crate trying to figure out what was going on. After a bunch
of different compiler errors and searching on the internet, I found the issue
was with &lt;em>the filename of my target JSON&lt;/em>. So some part of the code or build
process uses the filename of the JSON, which was &lt;code>cosmo.json&lt;/code> at that time, but
it specifically needs a target name like &lt;code>x86_64-linux-unknown-cosmo&lt;/code>, otherwise
some &lt;del>ifdef&lt;/del> &lt;code>cfg_if&lt;/code> falls through and breaks a bunch of things. Why does the
name of the JSON matter? I don&amp;rsquo;t know, but I&amp;rsquo;m happy that this bug doesn&amp;rsquo;t
bother me anymore.&lt;/p>
&lt;p>The next &amp;ldquo;bug&amp;rdquo; is more a comment about &lt;code>cargo&lt;/code>, and is probably because I&amp;rsquo;m
still new to Rust. &lt;code>cargo&lt;/code> is a wonderful package manager, and building
projects is pretty smooth. But once it comes to building the &lt;code>std&lt;/code> crate, some
of the convenience disappears, and I&amp;rsquo;d like a bit more flexibility in specifying
what I want cargo to do. I&amp;rsquo;m building a static executable, and I&amp;rsquo;d like to say,
&amp;ldquo;okay &lt;code>cargo&lt;/code> forget about linking &lt;code>-lunwind&lt;/code> or &lt;code>-lm&lt;/code> or whatever, just listen
to me, &lt;code>cosmopolitan.a&lt;/code> has everything you need for this&amp;rdquo;, but I couldn&amp;rsquo;t find
any combination of flags to communicate this. Eventually I gave up and wrote a
&lt;code>bash&lt;/code> script which just filtered out all the linker arguments I didn&amp;rsquo;t want
before calling &lt;code>gcc&lt;/code>.&lt;/p>
&lt;p>The last set of bugs were at the link stage &amp;ndash; I had every crate compiling
without error, but when linking the executable, I found that I was missing a few
symbols. Some were easy to add, like &lt;code>stat64&lt;/code> and &lt;code>__xpg_strerror_r&lt;/code>, but the
&lt;code>std&lt;/code> crate required the pthreads key API (&lt;code>pthread_key_create&lt;/code> etc.) to be
implemented, which was weird because I thought I had specified single-threaded
in &lt;code>cosmo.json&lt;/code>. Another dependency of the &lt;code>std&lt;/code> crate was
&lt;a href="https://github.com/rust-lang/backtrace-rs">&lt;code>backtrace&lt;/code>&lt;/a>, which requires
&lt;a href="https://github.com/libunwind/libunwind">&lt;code>libunwind&lt;/code>&lt;/a> in the default linux
builds even though there is a &lt;code>noop&lt;/code> crate that can be used for &lt;code>std&lt;/code>. I
couldn&amp;rsquo;t figure out the right flags to avoid these linker errors, so I wrote
&lt;a href="https://github.com/ahgamut/rust-ape-example/blob/f6ae82160c39814fcc99e2301aa266357e082bb1/libcosmo/stubs.c">some dumb
stubs&lt;/a>
to just get by the linker. A couple of days later, &lt;a href="https://github.com/jart">Justine
Tunney&lt;/a> implemented the pthreads key API in
Cosmopolitan Libc, and I asked Justine to add the &lt;code>libunwind&lt;/code> stubs as well so
&lt;code>backtrace&lt;/code> wouldn&amp;rsquo;t complain. I think there should be a &lt;code>cargo&lt;/code> flag or
something to choose using the &lt;code>noop&lt;/code> crate in &lt;code>backtrace&lt;/code> when compiling &lt;code>std&lt;/code>.&lt;/p>
&lt;p>Anyway, once I got through these linker errors, I downloaded the latest
&lt;code>cosmopolitan.zip&lt;/code> amalgamation from
&lt;a href="https://justine.lol/cosmopolitan/cosmopolitan.zip">here&lt;/a>, and now I could build
some Actually Portable Executables with Rust.&lt;/p>
&lt;h2 id="hello-world-and-a-few-examples">&lt;code>Hello World!&lt;/code> and a few examples&lt;/h2>
&lt;p>Rust is Actually Portable: here&amp;rsquo;s the hello world program that uses Rust and
Cosmopolitan Libc:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="k">fn&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="fm">println!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;Hello World! This is an APE built with Rust.&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>That&amp;rsquo;s it. No unsafe, no changes to the Rust &lt;code>std&lt;/code> source code. You just need to
provide the right flags to &lt;code>cargo&lt;/code>, and done. I also picked the first few
examples from &lt;a href="https://doc.rust-lang.org/rust-by-example/">Rust By Example&lt;/a> to
build and try, and they all worked as expected. I&amp;rsquo;ve not tried a lot of things,
so there&amp;rsquo;s room for experimentation and submitting PRs with Rust code (like with
&lt;code>backtrace&lt;/code>) and to Cosmopolitan Libc (implementing the &lt;code>libunwind&lt;/code> stubs or
filling out the pthreads API).&lt;/p>
&lt;h2 id="closing-notes">Closing Notes&lt;/h2>
&lt;p>I feel the package manager and documentation of Rust are big reasons why it is
so popular. Being new to Rust, I was able to learn about safe vs unsafe, the
&lt;code>libc&lt;/code> crate, &lt;code>cargo&lt;/code>, the &lt;code>std&lt;/code> crate, &lt;code>backtrace&lt;/code>, &lt;code>panic&lt;/code>, &lt;code>rustc&lt;/code>, and what
Rust-generated assembly looked like, all over maybe a couple of weekend
afternoons. Cosmopolitan Libc provided a unique angle to tour Rust, and it was a
&lt;em>lot of fun&lt;/em> to discover all of this.&lt;/p>
&lt;p>Last March, Lua was the first language to be ported to Cosmopolitan Libc. At
that time, parts of the libc API were still missing; when porting Python I
submitted PRs for &lt;code>getnameinfo&lt;/code>, &lt;code>struct servent&lt;/code> etc. so Python&amp;rsquo;s &lt;code>socket&lt;/code>
library would work. But since that time a lot of work has been put into
Cosmopolitan Libc, so that software built on it can be fun to develop and fast.
The almost-complete libc API has made it so much easier to port software &amp;ndash; Rust
just needed a JSON file and some flags to &lt;code>cargo&lt;/code>! I&amp;rsquo;m pretty sure a lot of
software can be built with Cosmopolitan Libc, it&amp;rsquo;s just a matter of convincing
the build system. If someone figures out a way to even partially automate this
(say like &lt;a href="https://www.freebsd.org/ports/">FreeBSD&amp;rsquo;s ports&lt;/a>), that would be
amazing.&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>As of this writing (2022-07-27), I&amp;rsquo;ve ported the following software to
Cosmopolitan Libc: &lt;a href="https://github.com/ahgamut/lua">Lua&lt;/a> and
&lt;a href="https://github.com/jart/cosmopolitan/pull/162">SQLite&lt;/a>, both of which are
now vendored in the Cosmopolitan monorepo and part of
&lt;a href="https://justine.lol/redbean2">&lt;code>redbean&lt;/code>&lt;/a>,
&lt;a href="https://github.com/ahgamut/cpython/tree/cosmo_py36">Python3.6&lt;/a>, and &lt;a href="https://github.com/jart/cosmopolitan/pull/305">GNU
Make&lt;/a>, both of which are part
of the Cosmopolitan monorepo, &lt;a href="https://github.com/ahgamut/janet">Janet&lt;/a>,
&lt;a href="https://github.com/ahgamut/cpython/tree/cosmo_py27">Python2.7&lt;/a>,
&lt;a href="https://github.com/ahgamut/php-src">PHP7.3&lt;/a>,
&lt;a href="https://github.com/ahgamut/tcl">tcl8.6&lt;/a>,
&lt;a href="https://github.com/ahgamut/LuaJIT-cosmo">LuaJIT&lt;/a>, QuickJS, OpenSSL1.1.1k,
&lt;code>zip/unzip&lt;/code>, &lt;code>gzip&lt;/code>, &lt;code>bzip2&lt;/code>, the &lt;a href="https://github.com/ahgamut/blis">BLIS acceleration
library&lt;/a> because I&amp;rsquo;m trying to get numpy,
and a bunch of CPython extensions like &lt;code>greenlet&lt;/code> and &lt;code>markupsafe&lt;/code>. I&amp;rsquo;m sure
I&amp;rsquo;ve forgotten a couple, and I&amp;rsquo;m not noting all the libraries that I haven&amp;rsquo;t
successfully built yet.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Netpicking Part 3: Prediction Sets</title><link>https://ahgamut.github.io/2021/11/24/netpicking-3/</link><pubDate>Wed, 24 Nov 2021 00:00:00 +0000</pubDate><guid>https://ahgamut.github.io/2021/11/24/netpicking-3/</guid><description>&lt;p>It&amp;rsquo;s been a while since I looked at &lt;code>mnistk&lt;/code>. Recently, I came across this
&lt;a href="https://arxiv.org/abs/2009.14193">interesting paper&lt;/a> which describes something
called &lt;em>Regularized Adaptive Prediction Sets&lt;/em> (RAPS), a technique for
uncertainty estimation. The RAPS algorithm wraps a model&amp;rsquo;s prediction scores to
output a set that contains the true value with high probability for a given
confidence level $\alpha$. Basically, instead of getting a single class output
(&amp;ldquo;this image is a squirrel&amp;rdquo;), we can now get a set. See the example from the
paper:&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/raps-paper.png" alt="example of prediction sets">&lt;/p>
&lt;p>My original &lt;code>mnistk&lt;/code> post used the analogy of an exam to select the best
network. Let&amp;rsquo;s continue with that here. If a single output is like filling in a
bubble in a multiple-choice test, then a prediction set output is like &amp;hellip;
shoddily filling in multiple bubbles.&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/raps-bubbles.png" alt="would&amp;rsquo;ve filled more bubbles if I knew about prediction sets back then">&lt;/p>
&lt;p>This post is about using RAPS to help me choose the best network from &lt;code>mnistk&lt;/code>.&lt;/p>
&lt;h2 id="getting-the-data">Getting the data&lt;/h2>
&lt;p>I implemented the RAPS algorithm for &lt;code>mnistk&lt;/code> &lt;a href="https://github.com/ahgamut/mnistk/tree/master">a while
back&lt;/a>, but I didn&amp;rsquo;t get the time
to test it out. The RAPS algorithm requires a &lt;em>calibration dataset&lt;/em> when
initializing the wrapper logic. I used the first 10000 samples from the &lt;a href="https://github.com/facebookresearch/qmnist">QMNIST
dataset&lt;/a> for calibration, and the
remaining 50000 samples as test data to obtain prediction sets. The original
&lt;code>mnistk&lt;/code> networks had 1001 networks and 12 snapshots per network. That gives
1001 x 12 x 50000 = 600.6 million prediction set data to look at.&lt;/p>
&lt;p>It took around 20 hours (on some AWS EC2 &lt;code>torch&lt;/code> &lt;code>cpuonly&lt;/code> system) to get this
data. I found that my implementation of the RAPS algorithm got a &lt;a href="https://github.com/ahgamut/mnistk/tree/raps-vectorize">2x
speedup&lt;/a> if I did all the
&lt;code>torch&lt;/code> neural network stuff first, and then used numpy vectorization to process
the scores for calibration and testing.&lt;/p>
&lt;h2 id="plotting-helps--but-not-much">Plotting helps &amp;hellip; but not much&lt;/h2>
&lt;p>Simple things first, let&amp;rsquo;s look at how prediction set size is related to accuracy:&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/raps-scatter.png" alt="score1">&lt;/p>
&lt;p>Okay, prediction set size seems to follow a linear-ish relationship to the accuracy
of the network. I did a bunch of other plots similar to the ones in &lt;a href="https://ahgamut.github.io/2020/11/20/netpicking-1/">Part 1&lt;/a>
which showed similar group characteristics. But these plots aren&amp;rsquo;t helping me as
much with what I want: I want some metric to help me pick the best network.&lt;/p>
&lt;h2 id="looking-at-the-top-10">Looking at the top 10&lt;/h2>
&lt;p>Let&amp;rsquo;s look at the top 10 networks in terms of accuracy: I&amp;rsquo;ll use &lt;code>num_c&lt;/code>, the
number of correct answers (out of 50000). For simplicity, I picked the best
performing snapshot for each network, leaving us with 1001 entries.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">name&lt;/th>
&lt;th style="text-align:right">accuracy_rank&lt;/th>
&lt;th style="text-align:right">num_c&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_85&lt;/td>
&lt;td style="text-align:right">1&lt;/td>
&lt;td style="text-align:right">49636&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_71&lt;/td>
&lt;td style="text-align:right">2&lt;/td>
&lt;td style="text-align:right">49610&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_56&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;td style="text-align:right">49599&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_58&lt;/td>
&lt;td style="text-align:right">4&lt;/td>
&lt;td style="text-align:right">49597&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_69&lt;/td>
&lt;td style="text-align:right">5&lt;/td>
&lt;td style="text-align:right">49582&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_81&lt;/td>
&lt;td style="text-align:right">6&lt;/td>
&lt;td style="text-align:right">49572&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_89&lt;/td>
&lt;td style="text-align:right">7&lt;/td>
&lt;td style="text-align:right">49569&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Conv2dReLU_14&lt;/td>
&lt;td style="text-align:right">8&lt;/td>
&lt;td style="text-align:right">49558&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_66&lt;/td>
&lt;td style="text-align:right">9&lt;/td>
&lt;td style="text-align:right">49552&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_83&lt;/td>
&lt;td style="text-align:right">10&lt;/td>
&lt;td style="text-align:right">49544&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>As expected, &lt;code>ResnetStyle&lt;/code> models dominate. But the above scatterplot said
prediction set sizes are closely related to accuracy. Let&amp;rsquo;s call a prediction
with only one element in the prediction set as a &lt;em>sure&lt;/em> prediction. Let&amp;rsquo;s look
at the top 10 networks in terms of &lt;code>num_s&lt;/code> the number of predictions about which
they are sure:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">name&lt;/th>
&lt;th style="text-align:right">accuracy_rank&lt;/th>
&lt;th style="text-align:right">num_s&lt;/th>
&lt;th style="text-align:right">num_c&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">Conv2dSELU_6&lt;/td>
&lt;td style="text-align:right">136&lt;/td>
&lt;td style="text-align:right">49568&lt;/td>
&lt;td style="text-align:right">49212&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_58&lt;/td>
&lt;td style="text-align:right">4&lt;/td>
&lt;td style="text-align:right">49498&lt;/td>
&lt;td style="text-align:right">49597&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_71&lt;/td>
&lt;td style="text-align:right">2&lt;/td>
&lt;td style="text-align:right">49442&lt;/td>
&lt;td style="text-align:right">49610&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_56&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;td style="text-align:right">49440&lt;/td>
&lt;td style="text-align:right">49599&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_81&lt;/td>
&lt;td style="text-align:right">6&lt;/td>
&lt;td style="text-align:right">49425&lt;/td>
&lt;td style="text-align:right">49572&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Conv2dReLU_14&lt;/td>
&lt;td style="text-align:right">8&lt;/td>
&lt;td style="text-align:right">49383&lt;/td>
&lt;td style="text-align:right">49558&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_85&lt;/td>
&lt;td style="text-align:right">1&lt;/td>
&lt;td style="text-align:right">49379&lt;/td>
&lt;td style="text-align:right">49636&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_47&lt;/td>
&lt;td style="text-align:right">11&lt;/td>
&lt;td style="text-align:right">49337&lt;/td>
&lt;td style="text-align:right">49541&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_89&lt;/td>
&lt;td style="text-align:right">7&lt;/td>
&lt;td style="text-align:right">49321&lt;/td>
&lt;td style="text-align:right">49569&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_88&lt;/td>
&lt;td style="text-align:right">33&lt;/td>
&lt;td style="text-align:right">49319&lt;/td>
&lt;td style="text-align:right">49497&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Where did &lt;code>Conv2dSELU_6&lt;/code> come from!? Somehow it is dominating in terms of
minimal prediction set size. If I deployed this model in the real world, I would
rarely see any uncertainty reported along with its predictions. But it is not in
the top 10 for accuracy; in fact its rank is &lt;code>136&lt;/code>, nowhere close to the top, so
from where is it getting all that confidence?&lt;/p>
&lt;p>Alright, best of both worlds. I want a model that not only gets a lot of answers
correct, but also is sure (highly confident) about the correct answers it gets.
Let&amp;rsquo;s look at the top 10 networks in terms of &lt;code>num_cs&lt;/code>, the number of correct
answers in which they are sure:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">name&lt;/th>
&lt;th style="text-align:right">accuracy_rank&lt;/th>
&lt;th style="text-align:right">num_c&lt;/th>
&lt;th style="text-align:right">num_s&lt;/th>
&lt;th style="text-align:right">num_cs&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_58&lt;/td>
&lt;td style="text-align:right">4&lt;/td>
&lt;td style="text-align:right">49597&lt;/td>
&lt;td style="text-align:right">49498&lt;/td>
&lt;td style="text-align:right">49306&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_56&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;td style="text-align:right">49599&lt;/td>
&lt;td style="text-align:right">49440&lt;/td>
&lt;td style="text-align:right">49260&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_71&lt;/td>
&lt;td style="text-align:right">2&lt;/td>
&lt;td style="text-align:right">49610&lt;/td>
&lt;td style="text-align:right">49442&lt;/td>
&lt;td style="text-align:right">49258&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_85&lt;/td>
&lt;td style="text-align:right">1&lt;/td>
&lt;td style="text-align:right">49636&lt;/td>
&lt;td style="text-align:right">49379&lt;/td>
&lt;td style="text-align:right">49237&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_81&lt;/td>
&lt;td style="text-align:right">6&lt;/td>
&lt;td style="text-align:right">49572&lt;/td>
&lt;td style="text-align:right">49425&lt;/td>
&lt;td style="text-align:right">49211&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Conv2dReLU_14&lt;/td>
&lt;td style="text-align:right">8&lt;/td>
&lt;td style="text-align:right">49558&lt;/td>
&lt;td style="text-align:right">49383&lt;/td>
&lt;td style="text-align:right">49181&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_47&lt;/td>
&lt;td style="text-align:right">11&lt;/td>
&lt;td style="text-align:right">49541&lt;/td>
&lt;td style="text-align:right">49337&lt;/td>
&lt;td style="text-align:right">49128&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_89&lt;/td>
&lt;td style="text-align:right">7&lt;/td>
&lt;td style="text-align:right">49569&lt;/td>
&lt;td style="text-align:right">49321&lt;/td>
&lt;td style="text-align:right">49127&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_92&lt;/td>
&lt;td style="text-align:right">20&lt;/td>
&lt;td style="text-align:right">49526&lt;/td>
&lt;td style="text-align:right">49272&lt;/td>
&lt;td style="text-align:right">49090&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_88&lt;/td>
&lt;td style="text-align:right">33&lt;/td>
&lt;td style="text-align:right">49497&lt;/td>
&lt;td style="text-align:right">49319&lt;/td>
&lt;td style="text-align:right">49087&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Now the top 10 is seeing some shakeups! The original &amp;ldquo;best&amp;rdquo; network is sometimes
not sure when being correct, so it falls down the rankings. What happens when
the model&amp;rsquo;s predictions are &lt;em>wrong&lt;/em> (don&amp;rsquo;t match with ground truth) or the model
is &lt;em>unsure&lt;/em> about the predictions (set size is greater than 1)?&lt;/p>
&lt;p>Each prediction made by the model can fall into one of four classes:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>sure&lt;/th>
&lt;th>unsure&lt;/th>
&lt;th>total&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>correct&lt;/td>
&lt;td>&lt;code>num_cs&lt;/code>&lt;/td>
&lt;td>&lt;code>num_cu&lt;/code>&lt;/td>
&lt;td>&lt;code>num_c&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>wrong&lt;/td>
&lt;td>&lt;code>num_ws&lt;/code>&lt;/td>
&lt;td>&lt;code>num_wu&lt;/code>&lt;/td>
&lt;td>&lt;code>num_w&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>total&lt;/td>
&lt;td>&lt;code>num_s&lt;/code>&lt;/td>
&lt;td>&lt;code>num_u&lt;/code>&lt;/td>
&lt;td>50000&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>&lt;code>num_cs&lt;/code> -&amp;gt; the model guessed correctly, and prediction size is 1. Ideally, all the model&amp;rsquo;s predictions would be here.&lt;/li>
&lt;li>&lt;code>num_cu&lt;/code> -&amp;gt; the model guessed correctly, but the prediction set size is greater than 1. This means the model&amp;rsquo;s prediction still has a nonzero chance of being something else. These predictions are okay, but not as reassuring as &lt;code>num_cs&lt;/code>, and may require a second look. Ideally, &lt;code>num_cs&lt;/code> would be zero, a high value indicates this model needs confirmation checks quite frequently.&lt;/li>
&lt;li>&lt;code>num_ws&lt;/code> -&amp;gt; the model guessed wrongly, and prediction size is 1. This means the model is sure about a prediction that does not match the ground truth. These predictions are bad, because the confidence means the prediction will not be second-guessed. Ideally, &lt;code>num_ws&lt;/code> would be zero, but a non-zero value may indicate some difficult samples or incorrectly labeled data.&lt;/li>
&lt;li>&lt;code>num_wu&lt;/code> -&amp;gt; the model guessed wrongly, the prediction set size is greater than 1, and the correct answer &lt;em>does not appear in the prediction set&lt;/em>. These predictions are bad, but not as bad as &lt;code>num_ws&lt;/code>, because they indicate a second check might be needed. However, the issue is when the backup check can return an answer that is not there in the prediction set, which may cause confusion.&lt;/li>
&lt;/ul>
&lt;p>Hmm &lt;code>num_wu&lt;/code> indicates there is a fifth class of predictions:&lt;/p>
&lt;ul>
&lt;li>&lt;code>num_we&lt;/code> -&amp;gt; the model guessed wrongly, the prediction set size is greater than 1, but the correct answer exists in the prediction set. These predictions are weird, because the backup check will resolve the uncertainty, so why are they made in the first place? Why is the correct answer hiding in the prediction set instead of being the first guess?&lt;/li>
&lt;/ul>
&lt;p>Let&amp;rsquo;s look at the top 10 again with these five quantities:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">name&lt;/th>
&lt;th style="text-align:right">accuracy_rank&lt;/th>
&lt;th style="text-align:right">num_cs&lt;/th>
&lt;th style="text-align:right">num_cu&lt;/th>
&lt;th style="text-align:right">num_ws&lt;/th>
&lt;th style="text-align:right">num_wu&lt;/th>
&lt;th style="text-align:right">num_we&lt;/th>
&lt;th style="text-align:right">num_sum5&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_58&lt;/td>
&lt;td style="text-align:right">4&lt;/td>
&lt;td style="text-align:right">49306&lt;/td>
&lt;td style="text-align:right">291&lt;/td>
&lt;td style="text-align:right">192&lt;/td>
&lt;td style="text-align:right">29&lt;/td>
&lt;td style="text-align:right">182&lt;/td>
&lt;td style="text-align:right">50000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_56&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;td style="text-align:right">49260&lt;/td>
&lt;td style="text-align:right">339&lt;/td>
&lt;td style="text-align:right">180&lt;/td>
&lt;td style="text-align:right">21&lt;/td>
&lt;td style="text-align:right">200&lt;/td>
&lt;td style="text-align:right">50000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_71&lt;/td>
&lt;td style="text-align:right">2&lt;/td>
&lt;td style="text-align:right">49258&lt;/td>
&lt;td style="text-align:right">352&lt;/td>
&lt;td style="text-align:right">184&lt;/td>
&lt;td style="text-align:right">25&lt;/td>
&lt;td style="text-align:right">181&lt;/td>
&lt;td style="text-align:right">50000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_85&lt;/td>
&lt;td style="text-align:right">1&lt;/td>
&lt;td style="text-align:right">49237&lt;/td>
&lt;td style="text-align:right">399&lt;/td>
&lt;td style="text-align:right">142&lt;/td>
&lt;td style="text-align:right">25&lt;/td>
&lt;td style="text-align:right">197&lt;/td>
&lt;td style="text-align:right">50000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_81&lt;/td>
&lt;td style="text-align:right">6&lt;/td>
&lt;td style="text-align:right">49211&lt;/td>
&lt;td style="text-align:right">361&lt;/td>
&lt;td style="text-align:right">214&lt;/td>
&lt;td style="text-align:right">23&lt;/td>
&lt;td style="text-align:right">191&lt;/td>
&lt;td style="text-align:right">50000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Conv2dReLU_14&lt;/td>
&lt;td style="text-align:right">8&lt;/td>
&lt;td style="text-align:right">49181&lt;/td>
&lt;td style="text-align:right">377&lt;/td>
&lt;td style="text-align:right">202&lt;/td>
&lt;td style="text-align:right">29&lt;/td>
&lt;td style="text-align:right">211&lt;/td>
&lt;td style="text-align:right">50000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_47&lt;/td>
&lt;td style="text-align:right">11&lt;/td>
&lt;td style="text-align:right">49128&lt;/td>
&lt;td style="text-align:right">413&lt;/td>
&lt;td style="text-align:right">209&lt;/td>
&lt;td style="text-align:right">32&lt;/td>
&lt;td style="text-align:right">218&lt;/td>
&lt;td style="text-align:right">50000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_89&lt;/td>
&lt;td style="text-align:right">7&lt;/td>
&lt;td style="text-align:right">49127&lt;/td>
&lt;td style="text-align:right">442&lt;/td>
&lt;td style="text-align:right">194&lt;/td>
&lt;td style="text-align:right">23&lt;/td>
&lt;td style="text-align:right">214&lt;/td>
&lt;td style="text-align:right">50000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_92&lt;/td>
&lt;td style="text-align:right">20&lt;/td>
&lt;td style="text-align:right">49090&lt;/td>
&lt;td style="text-align:right">436&lt;/td>
&lt;td style="text-align:right">182&lt;/td>
&lt;td style="text-align:right">37&lt;/td>
&lt;td style="text-align:right">255&lt;/td>
&lt;td style="text-align:right">50000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_88&lt;/td>
&lt;td style="text-align:right">33&lt;/td>
&lt;td style="text-align:right">49087&lt;/td>
&lt;td style="text-align:right">410&lt;/td>
&lt;td style="text-align:right">232&lt;/td>
&lt;td style="text-align:right">36&lt;/td>
&lt;td style="text-align:right">235&lt;/td>
&lt;td style="text-align:right">50000&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>How can we use the information about the models' less-than-ideal predictions
(everything except &lt;code>num_cs&lt;/code>) to find the best network? Keeping with the analogy,
we can have negative marking, that nasty troll from &lt;a href="https://www.quora.com/How-can-I-handle-negative-marking-in-competitive-exams-if-I-am-not-100-sure-about-the-answer">competitive
exams&lt;/a>.
First let&amp;rsquo;s subtract a mark for each unsure or incorrect answer:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">name&lt;/th>
&lt;th style="text-align:right">accuracy_rank&lt;/th>
&lt;th style="text-align:right">cs - all&lt;/th>
&lt;th style="text-align:right">num_cs&lt;/th>
&lt;th style="text-align:right">num_cu&lt;/th>
&lt;th style="text-align:right">num_ws&lt;/th>
&lt;th style="text-align:right">num_wu&lt;/th>
&lt;th style="text-align:right">num_we&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_58&lt;/td>
&lt;td style="text-align:right">4&lt;/td>
&lt;td style="text-align:right">48612&lt;/td>
&lt;td style="text-align:right">49306&lt;/td>
&lt;td style="text-align:right">291&lt;/td>
&lt;td style="text-align:right">192&lt;/td>
&lt;td style="text-align:right">29&lt;/td>
&lt;td style="text-align:right">182&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_56&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;td style="text-align:right">48520&lt;/td>
&lt;td style="text-align:right">49260&lt;/td>
&lt;td style="text-align:right">339&lt;/td>
&lt;td style="text-align:right">180&lt;/td>
&lt;td style="text-align:right">21&lt;/td>
&lt;td style="text-align:right">200&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_71&lt;/td>
&lt;td style="text-align:right">2&lt;/td>
&lt;td style="text-align:right">48516&lt;/td>
&lt;td style="text-align:right">49258&lt;/td>
&lt;td style="text-align:right">352&lt;/td>
&lt;td style="text-align:right">184&lt;/td>
&lt;td style="text-align:right">25&lt;/td>
&lt;td style="text-align:right">181&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_85&lt;/td>
&lt;td style="text-align:right">1&lt;/td>
&lt;td style="text-align:right">48474&lt;/td>
&lt;td style="text-align:right">49237&lt;/td>
&lt;td style="text-align:right">399&lt;/td>
&lt;td style="text-align:right">142&lt;/td>
&lt;td style="text-align:right">25&lt;/td>
&lt;td style="text-align:right">197&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_81&lt;/td>
&lt;td style="text-align:right">6&lt;/td>
&lt;td style="text-align:right">48422&lt;/td>
&lt;td style="text-align:right">49211&lt;/td>
&lt;td style="text-align:right">361&lt;/td>
&lt;td style="text-align:right">214&lt;/td>
&lt;td style="text-align:right">23&lt;/td>
&lt;td style="text-align:right">191&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Conv2dReLU_14&lt;/td>
&lt;td style="text-align:right">8&lt;/td>
&lt;td style="text-align:right">48362&lt;/td>
&lt;td style="text-align:right">49181&lt;/td>
&lt;td style="text-align:right">377&lt;/td>
&lt;td style="text-align:right">202&lt;/td>
&lt;td style="text-align:right">29&lt;/td>
&lt;td style="text-align:right">211&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_47&lt;/td>
&lt;td style="text-align:right">11&lt;/td>
&lt;td style="text-align:right">48256&lt;/td>
&lt;td style="text-align:right">49128&lt;/td>
&lt;td style="text-align:right">413&lt;/td>
&lt;td style="text-align:right">209&lt;/td>
&lt;td style="text-align:right">32&lt;/td>
&lt;td style="text-align:right">218&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_89&lt;/td>
&lt;td style="text-align:right">7&lt;/td>
&lt;td style="text-align:right">48254&lt;/td>
&lt;td style="text-align:right">49127&lt;/td>
&lt;td style="text-align:right">442&lt;/td>
&lt;td style="text-align:right">194&lt;/td>
&lt;td style="text-align:right">23&lt;/td>
&lt;td style="text-align:right">214&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_92&lt;/td>
&lt;td style="text-align:right">20&lt;/td>
&lt;td style="text-align:right">48180&lt;/td>
&lt;td style="text-align:right">49090&lt;/td>
&lt;td style="text-align:right">436&lt;/td>
&lt;td style="text-align:right">182&lt;/td>
&lt;td style="text-align:right">37&lt;/td>
&lt;td style="text-align:right">255&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_88&lt;/td>
&lt;td style="text-align:right">33&lt;/td>
&lt;td style="text-align:right">48174&lt;/td>
&lt;td style="text-align:right">49087&lt;/td>
&lt;td style="text-align:right">410&lt;/td>
&lt;td style="text-align:right">232&lt;/td>
&lt;td style="text-align:right">36&lt;/td>
&lt;td style="text-align:right">235&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>That didn&amp;rsquo;t change the order at all, so let&amp;rsquo;s have weighted negative marking.&lt;/p>
&lt;ul>
&lt;li>Being sure about a wrong answer (&lt;code>num_ws&lt;/code>) is clearly the worst thing to do, gets a weight of &amp;hellip; let&amp;rsquo;s say 12.&lt;/li>
&lt;li>Being unsure about a wrong answer but not considering the correct answer (&lt;code>num_wu&lt;/code>) gets a weight of 9.&lt;/li>
&lt;li>Being unsure about a wrong answer but at least considering the correct answer (&lt;code>num_we&lt;/code>) gets a weight of 8.&lt;/li>
&lt;li>Being unsure about a correct answer (&lt;code>num_cu&lt;/code>) gets a weight of 6.&lt;/li>
&lt;/ul>
&lt;p>Now let&amp;rsquo;s see if the top 10 shift:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">name&lt;/th>
&lt;th style="text-align:right">accuracy_rank&lt;/th>
&lt;th style="text-align:right">cs - weighted&lt;/th>
&lt;th style="text-align:right">num_cs&lt;/th>
&lt;th style="text-align:right">num_cu&lt;/th>
&lt;th style="text-align:right">num_ws&lt;/th>
&lt;th style="text-align:right">num_wu&lt;/th>
&lt;th style="text-align:right">num_we&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_58&lt;/td>
&lt;td style="text-align:right">4&lt;/td>
&lt;td style="text-align:right">43539&lt;/td>
&lt;td style="text-align:right">49306&lt;/td>
&lt;td style="text-align:right">291&lt;/td>
&lt;td style="text-align:right">192&lt;/td>
&lt;td style="text-align:right">29&lt;/td>
&lt;td style="text-align:right">182&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_85&lt;/td>
&lt;td style="text-align:right">1&lt;/td>
&lt;td style="text-align:right">43338&lt;/td>
&lt;td style="text-align:right">49237&lt;/td>
&lt;td style="text-align:right">399&lt;/td>
&lt;td style="text-align:right">142&lt;/td>
&lt;td style="text-align:right">25&lt;/td>
&lt;td style="text-align:right">197&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_56&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;td style="text-align:right">43277&lt;/td>
&lt;td style="text-align:right">49260&lt;/td>
&lt;td style="text-align:right">339&lt;/td>
&lt;td style="text-align:right">180&lt;/td>
&lt;td style="text-align:right">21&lt;/td>
&lt;td style="text-align:right">200&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_71&lt;/td>
&lt;td style="text-align:right">2&lt;/td>
&lt;td style="text-align:right">43265&lt;/td>
&lt;td style="text-align:right">49258&lt;/td>
&lt;td style="text-align:right">352&lt;/td>
&lt;td style="text-align:right">184&lt;/td>
&lt;td style="text-align:right">25&lt;/td>
&lt;td style="text-align:right">181&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_81&lt;/td>
&lt;td style="text-align:right">6&lt;/td>
&lt;td style="text-align:right">42742&lt;/td>
&lt;td style="text-align:right">49211&lt;/td>
&lt;td style="text-align:right">361&lt;/td>
&lt;td style="text-align:right">214&lt;/td>
&lt;td style="text-align:right">23&lt;/td>
&lt;td style="text-align:right">191&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Conv2dReLU_14&lt;/td>
&lt;td style="text-align:right">8&lt;/td>
&lt;td style="text-align:right">42546&lt;/td>
&lt;td style="text-align:right">49181&lt;/td>
&lt;td style="text-align:right">377&lt;/td>
&lt;td style="text-align:right">202&lt;/td>
&lt;td style="text-align:right">29&lt;/td>
&lt;td style="text-align:right">211&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_89&lt;/td>
&lt;td style="text-align:right">7&lt;/td>
&lt;td style="text-align:right">42228&lt;/td>
&lt;td style="text-align:right">49127&lt;/td>
&lt;td style="text-align:right">442&lt;/td>
&lt;td style="text-align:right">194&lt;/td>
&lt;td style="text-align:right">23&lt;/td>
&lt;td style="text-align:right">214&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_47&lt;/td>
&lt;td style="text-align:right">11&lt;/td>
&lt;td style="text-align:right">42110&lt;/td>
&lt;td style="text-align:right">49128&lt;/td>
&lt;td style="text-align:right">413&lt;/td>
&lt;td style="text-align:right">209&lt;/td>
&lt;td style="text-align:right">32&lt;/td>
&lt;td style="text-align:right">218&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_69&lt;/td>
&lt;td style="text-align:right">5&lt;/td>
&lt;td style="text-align:right">41998&lt;/td>
&lt;td style="text-align:right">49075&lt;/td>
&lt;td style="text-align:right">507&lt;/td>
&lt;td style="text-align:right">167&lt;/td>
&lt;td style="text-align:right">23&lt;/td>
&lt;td style="text-align:right">228&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ResNetStyle_92&lt;/td>
&lt;td style="text-align:right">20&lt;/td>
&lt;td style="text-align:right">41917&lt;/td>
&lt;td style="text-align:right">49090&lt;/td>
&lt;td style="text-align:right">436&lt;/td>
&lt;td style="text-align:right">182&lt;/td>
&lt;td style="text-align:right">37&lt;/td>
&lt;td style="text-align:right">255&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Indeed they did: the overall rankings shifted, and a network from the original
top 10 (&lt;code>ResnetStyle_69&lt;/code>) sneaked back in because of the new scoring scale. Of
course, the weights I picked were arbitrary, but the point is that the
incorrect/unsure predictions also need to considered when trying to choose the
best network.&lt;/p>
&lt;h2 id="closing-notes">Closing Notes&lt;/h2>
&lt;p>Regularized Adaptive Prediction Sets (RAPS) provide additional context when I
need to choose the best network. Earlier, I could examine networks in terms of
accuracy/weights/memory use/training time. Now, with surface-level information
about the prediction sets (just set sizes), I can break down a raw accuracy
score into 5 different components, and choose the best network for my use case
by assigning weights for the types of errors I don&amp;rsquo;t want. This can be useful in
deployment: I am fine with networks on embedded devices having confidence issues
about predictions (especially for incorrect predictions). But complex networks
in the cloud should provide more confidence, because they are usually the last
resort. I am not certain (!) about what should be done when the initial
prediction is unsure, and the backup gives a different answer (the &lt;code>num_wu&lt;/code>
case) because that seems ripe for confusion.&lt;/p>
&lt;p>There are other interesting angles to examine. I want to see why that
&lt;code>Conv2dSELU_6&lt;/code> has so much confidence, and what means for the individual
predictions it makes. The RAPS algorithm provides two hyperparameters, $k$ and
$\lambda$ in addition to $\alpha$, and a wrapper to find the optimal $k$ and
$\lambda$ for a given network during calibration. I used the same $k$ and
$\lambda$ values throughout, so that leaves me to wonder how much the above
tables are affected if I use the optimal values. I have also not used the
calibrated scores or the generalized quantile values anywhere in the analysis.
That&amp;rsquo;s probably worth a separate round on AWS and another post.&lt;/p></description></item><item><title>Python is Actually Portable</title><link>https://ahgamut.github.io/2021/07/13/ape-python/</link><pubDate>Tue, 13 Jul 2021 00:00:00 +0000</pubDate><guid>https://ahgamut.github.io/2021/07/13/ape-python/</guid><description>&lt;p>&lt;strong>Update (2022-07-27)&lt;/strong> : This post describes a proof-of-concept Python
executable (2.7.18 and 3.6.14) built on &lt;a href="https://github.com/jart/cosmopolitan">Cosmopolitan
Libc&lt;/a>, which allows it to run on six
different operating systems (Linux, Mac, Windows, NetBSD, FreeBSD, OpenBSD).
It&amp;rsquo;s been more than a year since I put this together, and now Python3.6 and its
test suite are part of the &lt;a href="https://github.com/jart/cosmopolitan/pull/235">Cosmopolitan Libc
monorepo&lt;/a>. There&amp;rsquo;s been a LOT of
work done to improve &lt;code>python.com&lt;/code> over vanilla Python3.6 &amp;ndash; a custom
&lt;a href="https://github.com/jart/cosmopolitan/pull/425">&lt;code>sys.meta_path&lt;/code> entry&lt;/a> for
faster loading, &lt;a href="https://justine.lol/sizetricks#dzd">size reductions&lt;/a> of the
&lt;code>unicodedata&lt;/code>, a &lt;code>cosmo&lt;/code> module for Cosmopolitan-specific goodies, a revamp of
Python&amp;rsquo;s build and testing system, a superb REPL experience, backports from
Python 3.7, and a lot more! So some of the details in this blog post are likely
out of date. Check out the history of APE Python
&lt;a href="https://github.com/jart/cosmopolitan/issues/141">here&lt;/a>, build it via the
Cosmopolitan monorepo, or download &lt;code>python.com&lt;/code> from
&lt;a href="https://justine.lol/ftrace/python.com">here&lt;/a>. I&amp;rsquo;m also trying to port the newer
versions of Python and some well-known Python packages like numpy. Join the
discussion about Python and Cosmopolitan Libc in the
redbean Discord server: &lt;a href="https://discord.gg/rGQja6kS">https://discord.gg/rGQja6kS&lt;/a>&lt;/p>
&lt;p>Back in February, I put together &lt;a href="https://ahgamut.github.io/2021/02/27/ape-cosmo/">Lua 5.4&lt;/a> using &lt;a href="https://github.com/jart/cosmopolitan">Cosmopolitan
Libc&lt;/a> as a quick proof-of-concept, and that led to Lua 5.4 being
&lt;a href="https://github.com/jart/cosmopolitan/issues/61#issuecomment-792359199">vendored&lt;/a> as part of the Cosmopolitan repository on Github, along
with many other interesting developments. It&amp;rsquo;s pretty exciting to try and
compile well-known C projects using Cosmopolitan; the portability reward is
great motivation, and I get to observe the design, coding style, and build
system of high-quality codebases.&lt;/p>
&lt;p>However, my initial plan with Cosmopolitan was not to compile Lua, it was to
compile Python. Since February, I&amp;rsquo;ve been trying to understand how Cosmopolitan
works, reading the repo code and submitting PRs occasionally, and finally I have
an actually portable version of Python 2.7.18 (and 3.6.14&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>) &amp;ndash; you
can build it from the repository &lt;a href="https://github.com/ahgamut/cpython/tree/cosmo_py27">here&lt;/a>. It&amp;rsquo;s not solid as Lua 5.4
because it currently passes only a third of the regression tests, but most of
the parts are there. For example, here&amp;rsquo;s a GIF showing a simple &lt;a href="https://flask.palletsprojects.com/en/2.0.x/">Flask
webapp&lt;/a> running via the &lt;code>python.com&lt;/code> APE.&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/ape-python.gif" alt="webapp">&lt;/p>
&lt;p>It&amp;rsquo;s quite slow, but it works(tested on Debian Linux and Windows
10&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>), and there&amp;rsquo;s a lot of room for improvement. This post
describes the kinds of changes I made to get Python to work.&lt;/p>
&lt;h2 id="getting-python-to-compile">Getting Python to compile&lt;/h2>
&lt;p>Python 2.7.18 is built via the &lt;a href="https://en.wikipedia.org/wiki/Configure_script">&lt;code>configure&lt;/code> idiom&lt;/a>: the tarball
provides a &lt;code>configure&lt;/code> shell script which runs the necessary compatibility tests
for the host system/compiler. which then creates the Makefile for the actual
build, and fills &lt;code>pyconfig.h&lt;/code> with the necessary &lt;code>#define&lt;/code>s related to the
features available in the host system.&lt;/p>
&lt;p>I added dummy headers like for Lua, and wrote a &lt;code>superconfigure&lt;/code> script which
called &lt;code>configure&lt;/code> with the flags for the Cosmopolitan
&lt;a href="https://github.com/jart/cosmopolitan#getting-started">amalgamation&lt;/a>, like below:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">./configure --disable-shared &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> --without-threads --disable-ipv6 &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> &lt;span class="nv">CFLAGS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="nv">$COSMO_CFLAGS&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> &lt;span class="nv">LDFLAGS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="nv">$COSMO_LDFLAGS&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> &lt;span class="nv">LIBS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;cosmopolitan.a&amp;#34;&lt;/span>
make -j4
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This started the build, but almost every source file had complaints about
functions being re-declared. For example, the Makefile assumed that &lt;code>sinh&lt;/code> was
not available, and wrongly had &lt;code>#define HAVE_SINH 0&lt;/code>, which caused it to use
Python&amp;rsquo;s backup implementation.&lt;/p>
&lt;p>It turns out that the &lt;code>CFLAGS&lt;/code> provided for the cosmopolitan amalgamation
clashed with &lt;a href="https://www.gnu.org/software/autoconf/manual/autoconf-2.69/html_node/Generic-Functions.html">&lt;code>AC_CHECK_FUNC&lt;/code>&lt;/a>, which is what &lt;code>configure&lt;/code> scripts use
to check if the host provides a particular function. At the time, the simplest
fix was to edit the &lt;code>AC_CHECK_FUNC&lt;/code> part of &lt;code>configure&lt;/code> script to make it play
well, and it just worked&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>After that, fixing the remaining errors was mostly straightforward: add a few
&lt;code>#define&lt;/code>s or &lt;code>#undef&lt;/code>s to avoid missing functions, ensure the Makefile
performed the linking correctly, find-and-replace for name
clashes&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>, and so on.&lt;/p>
&lt;h2 id="running-the-base-interpreter">Running the base interpreter&lt;/h2>
&lt;p>I tried running the &lt;code>python.com&lt;/code> APE within the build directory, and it worked
without a hitch. But when I moved the executable somewhere, the interpreter
would start up and then exit with a failure &lt;code>unable to import site&lt;/code>: Python
checks for &lt;code>site.py&lt;/code> in &lt;code>sys.path&lt;/code> at startup, which sets up the import context
for the rest of the standard library (stuff like which OS the APE is on for
&lt;code>os.py&lt;/code>). Running &lt;code>python.com -S&lt;/code> fixed the issue&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>, and later I
added a few relative folder paths to &lt;code>sys.path&lt;/code> so that Python could search
there at startup.&lt;/p>
&lt;p>One annoying issue I faced with the &lt;code>python.com&lt;/code> REPL on Linux was I had to
press &lt;code>Return&lt;/code> twice when I wanted to enter an empty line to the REPL. By
running &lt;code>python.com -u&lt;/code> I found out this this was related to input buffering and
&lt;a href="https://en.cppreference.com/w/c/io/setvbuf">&lt;code>setvbuf&lt;/code>&lt;/a>: the interpreter was following Cosmopolitan&amp;rsquo;s choice of
buffering IO, so I added a couple of lines to use unbuffered input by default.&lt;/p>
&lt;p>When I tried &lt;code>python.com -S&lt;/code> on Windows, the interpreter would start, but then
every line I entered at the REPL would cause a syntax error. I thought this was
also related to &lt;code>setvbuf&lt;/code>, but this was because Windows &lt;a href="https://github.com/jart/cosmopolitan/issues/141#issuecomment-812918670">&lt;code>cmd.exe&lt;/code> sends
CRLF&lt;/a> on pressing &lt;code>Return&lt;/code>, and the interpreter expects only LF, so the CR
was read as incorrect syntax. It was straightforward to change the parser logic.&lt;/p>
&lt;h2 id="adding-standard-library-modules">Adding standard library modules&lt;/h2>
&lt;p>When the Makefile finishes building &lt;code>python&lt;/code>, it immediately tries to call a
&lt;code>setup.py&lt;/code> to build C extensions for the standard library. This was pretty
stupid: &lt;code>setup.py&lt;/code> tries to build and link a bunch of shared objects to the
interpreter even though I&amp;rsquo;ve specified a static build (&lt;code>--disable-shared&lt;/code>). I
found out it was doing this after I saw a successful build on the screen,
followed a deluge of (&lt;code>unable to link&lt;/code>/&lt;code>no dlopen&lt;/code>/&lt;code>Rdynamic specified but also static&lt;/code>) errors.&lt;/p>
&lt;p>There is a nice way to compile C extensions into Python statically: via
&lt;code>Modules/Setup&lt;/code>. This file follows a simple syntax to specify extensions and
their requirements, so that you can compile extensions before &lt;code>setup.py&lt;/code> is
called.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">*static*
&lt;span class="c1"># &amp;lt;name of extension&amp;gt; &amp;lt;source files in Modules folder&amp;gt; &amp;lt;includes&amp;gt; &amp;lt;links&amp;gt; -DSOME_FLAG&lt;/span>
math mathmodule.c _math.c &lt;span class="c1"># -lm&lt;/span>
array arraymodule.c
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Calling &lt;code>make&lt;/code> after changing &lt;code>Modules/Setup&lt;/code> rebuilds the Makefile with the
necessary recipes for the specified extensions. You can read about
&lt;a href="https://github.com/ahgamut/cpython/blob/cosmo_py27/Modules/Setup">&lt;code>Modules/Setup&lt;/code> here&lt;/a>. One nasty aspect of this is if the syntax
in &lt;code>Modules/Setup&lt;/code> is wrong, the Makefile will be wrong, so you can&amp;rsquo;t run &lt;code>make&lt;/code>
even after you&amp;rsquo;ve fixed the error.&lt;/p>
&lt;p>I was able to compile a lot of modules into APE using &lt;code>Modules/Setup&lt;/code>: basic
modules like &lt;code>cPickle&lt;/code>, &lt;code>zlib&lt;/code> etc., modules that required external libraries
like &lt;code>_sqlite&lt;/code>, &lt;code>_bz2&lt;/code>, &lt;code>readline&lt;/code>, &lt;code>_ctypes&lt;/code>&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup> etc., and even
&lt;strong>external packages&lt;/strong> that depend on simple C extensions, like
&lt;a href="https://github.com/python-greenlet/greenlet/">&lt;code>greenlet&lt;/code>&lt;/a>. It all boils down to writing the correct recipe in
&lt;code>Modules/Setup&lt;/code>, ensuring the necessary static libraries are available, and
checking that the glue code around the imports works correctly&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>The final annoyance with the stdlib python files was that I had to copy the
folder containing them alongside &lt;code>python.com&lt;/code>, but this got solved because
Cosmopolitan allows the APE to be used as a valid ZIP file. I just zipped up
&lt;code>Lib/&lt;/code> into the APE, &lt;em>added &lt;code>python.com&lt;/code> itself as an entry in &lt;code>sys.path&lt;/code>&lt;/em>, and
Python&amp;rsquo;s own &lt;a href="https://docs.python.org/2.7/library/zipimport.html">&lt;code>zipimport&lt;/code> package&lt;/a> handled the rest.&lt;/p>
&lt;h2 id="using-pip-and-external-packages">Using &lt;code>pip&lt;/code> and external packages&lt;/h2>
&lt;p>After compiling most of the standard library packages, I still couldn&amp;rsquo;t get
&lt;code>ensurepip&lt;/code> to work, because it relied on threads, and the standard &lt;code>threading&lt;/code>
module in Python would just raise an &lt;code>ImportError&lt;/code> if it could not find the
&lt;code>_thread&lt;/code> C extension. The fix was present within the stdlib: there is a module
called &lt;code>_dummy_thread&lt;/code>, which spoofs &lt;code>_thread&lt;/code> so that &lt;code>threading&lt;/code> doesn&amp;rsquo;t
complain&lt;sup id="fnref:8">&lt;a href="#fn:8" class="footnote-ref" role="doc-noteref">8&lt;/a>&lt;/sup>. After this, I was able to run &lt;code>ensurepip&lt;/code> to install
&lt;code>pip&lt;/code> and &lt;code>setuptools&lt;/code> in &lt;code>Lib/site-packages&lt;/code>.&lt;/p>
&lt;p>However, running &lt;code>python.com -m pip install&lt;/code> doesn&amp;rsquo;t work because the Python APE
doe not currently have SSL support. I tried providing &lt;code>http://pypi.org/simple&lt;/code>
as the index URL but &lt;code>pip&lt;/code> was adamant in not letting me get my way.&lt;/p>
&lt;p>I didn&amp;rsquo;t want to figure out how to add SSL support to the APE (I expect it
should be possible&lt;sup id="fnref:9">&lt;a href="#fn:9" class="footnote-ref" role="doc-noteref">9&lt;/a>&lt;/sup>), so I just cheated and downloaded the
packages manually. The arrangement to add packages works like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">mkdir -p Lib/site-packages
&lt;span class="c1"># specify python version to pip if necessary&lt;/span>
/usr/bin/python2 -m pip download flask -t .
&lt;span class="c1"># wheels are just ZIPs, use unzip if pip complains&lt;/span>
./python.com -m pip install flask*.whl -t ./Lib/site-packages
zip -qr ./python.com ./Lib/site-packages/
rm -rf ./*.whl ./Lib/site-packages/
./python.com -m flask --version
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Of course, you would have recompile the APE if you wanted to add any C
extensions.&lt;/p>
&lt;h2 id="closing-notes">Closing Notes&lt;/h2>
&lt;p>It is really convenient to have the same application work on
Linux/Windows/MacOS, but the techniques I have seen/used all have tradeoffs:
either for the developer in terms of design, testing, and safety/consistency, or
for the user in terms on application size and performance.&lt;/p>
&lt;p>Cosmopolitan Libc does come with some tradeoffs as well (static compilation, C
codebases, no multithreading (&lt;strong>Update 2022-07-27:&lt;/strong>, no multithreading &lt;em>yet&lt;/em>,
the pthreads API takes a while to fill)), but I think it is amazing that I can
send a &lt;code>python.com&lt;/code> executable of a few megabytes as a zip file to someone, have
them run it without worrying about the OS, and provide them a simple webapp with
a backend that works even without an internet connection.&lt;/p>
&lt;p>This successful &lt;code>python.com&lt;/code> experiment unlocks many interesting directions:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Is it possible to tune the performance of the &lt;code>python.com&lt;/code> APE? I don&amp;rsquo;t expect
it to get anywhere close to &lt;a href="https://redbean.dev/">&lt;code>redbean&lt;/code>&lt;/a>, but some speed
improvements would be nice because Python web frameworks are established and
easy to use.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Is there room for a custom build system to produce a single-file
size-optimized &lt;code>python.com&lt;/code> APE webapp? We saw that it is possible to add C
extensions, and even regular packages into the executable via &lt;code>zip&lt;/code>. If there
is a dependency resolver that accounts for stdlib imports, which then produces
a &lt;code>Modules/Setup&lt;/code> or some similar build script to compile extensions and add
only the necessary libraries, that would be awesome&lt;sup id="fnref:10">&lt;a href="#fn:10" class="footnote-ref" role="doc-noteref">10&lt;/a>&lt;/sup>. (&lt;strong>2022-07-27:&lt;/strong>
now the Cosmopolitan monorepo builds &lt;code>python.com&lt;/code> via a
&lt;a href="https://github.com/jart/cosmopolitan/blob/master/third_party/python/python.mk">Makefile&lt;/a>,
checks import dependencies at link-time, runs the Python test suite, and adds
all files to the APE internal ZIP store ready-to-use).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Regarding python packages with C extensions, the build process for adding them
to the APE is rather unwieldy (&lt;strong>2022-07-27&lt;/strong> adding C extensions to the APE
is much more elegant now because of the Cosmopolitan monorepo, see
&lt;a href="https://github.com/ahgamut/cosmopolitan/tree/import-mod-test">this&lt;/a>) because
of all the manual changes involved. Is there a way to automatically patch the
imports, or better yet, compile Python C extensions as shared libraries with
Cosmopolitan?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>I&amp;rsquo;ve managed to compile Lua, QuickJS, and now Python2.7 and
&lt;a href="https://github.com/ahgamut/cpython/tree/cosmo_py36">Python3.6&lt;/a>. Are there web-friendly languages that would benefit
more from a Cosmopolitan build? Maybe PHP, or Ruby, or even Go if the details
work out? Remains to be seen.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Did you click on this before reading the remainder of the post because you
were wondering about Python 3? I know Python 2.7 reached EOL last year, but
the Python 2.7 codebase was easier to read, change, and debug, so I was able
to get a better idea of where I had to make changes. I put together a Python
3.6.14 APE (build it from the repo &lt;a href="https://github.com/ahgamut/cpython/tree/cosmo_py36">here&lt;/a>), and it took much
less time and experimentation because I knew exactly where to look.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>I originally uploaded this post like twelve hours, in the excitement of
seeing a Flask webapp work on the APE. Unfortunately, I forgot to test
on Windows before putting the post out, and Windows, true to its nature
caused several annoyances which together took a couple of hours to sort
out. However, I think it ought to work now.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>I originally tried the complicated solution of writing a new configure
script from scratch, but I got lost in the docs for &lt;code>autoconf&lt;/code>, and resorted
to the simpler fix of just editing the shell script. This issue only
happened because I used dummy headers with the amalgamation; if you have the
Cosmopolitan repo nearby, you can use &lt;code>-isystem cosmopolitan/libc/isystem&lt;/code>
instead of &lt;code>-I dummy_headers -include cosmopolitan.h&lt;/code>, which would avoid
confusing &lt;code>configure&lt;/code>.&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>I remembered this a few days back: if a name in your C file
clashes with a header name somewhere, you can do something like:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">
&lt;span class="cp">#ifdef name
&lt;/span>&lt;span class="cp">#define name __name
&lt;/span>&lt;span class="cp">#undef name
&lt;/span>&lt;span class="cp">&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>and avoid the name clash instead of doing a find-and-replace.&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>Over the course of getting the APE to work, my muscle memory is to call
&lt;code>python -BESsuv&lt;/code>, which avoids a bunch of normal startup stuff and adds
stderr information about imports. This is super useful when building python,
but one time I was running a local script and couldn&amp;rsquo;t figure out why it was
failing before I saw that I had typed &lt;code>python -BESsuv script.py&lt;/code> every
single time.&amp;#160;&lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>I was pleasantly surprised to find out that &lt;code>_sqlite&lt;/code> and &lt;code>_bz2&lt;/code> could be
compiled, because I didn&amp;rsquo;t expect SQLite or libbz2 would be easy to compile
from source with Cosmopolitan. SQLite is now &lt;a href="https://github.com/jart/cosmopolitan/pull/162">vendored in the Cosmopolitan
repo&lt;/a>.&lt;/p>
&lt;p>On the other hand, I wanted &lt;code>readline&lt;/code> because I like to have the
(press-Up-arrow-for-previously-typed-line) in the REPL, but I didn&amp;rsquo;t know
how &lt;code>terminfo&lt;/code> worked. &lt;code>_ctypes&lt;/code> was also a disappointment because I had to
compile &lt;code>libffi&lt;/code> from source, and then I saw most of &lt;code>_ctypes&lt;/code>' use comes
from having &lt;code>dlopen&lt;/code>.&amp;#160;&lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>for example, &lt;code>greenlet&lt;/code> contains a C extension called &lt;code>_greenlet&lt;/code> which it
refers to by doing things like the following in &lt;code>__init__.py&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">
&lt;span class="kn">from&lt;/span> &lt;span class="nn">._greenlet&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">foo&lt;/span>
&lt;span class="kn">from&lt;/span> &lt;span class="nn">greenlet._greenlet&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">bar&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>now &lt;code>__init__.py&lt;/code> expects &lt;code>_greenlet.so&lt;/code> to be present in the same
directory, but that is not possible because the extension is compiled into
the interpreter statically. So I had to manually change this to use &lt;code>from _greenlet&lt;/code> without the dot. This also means I have to change the extension
name in the &lt;code>PyModuleDef&lt;/code> part of the C source code: it&amp;rsquo;s not
&lt;code>greenlet._greenlet&lt;/code> anymore, it&amp;rsquo;s just &lt;code>_greenlet&lt;/code>.&amp;#160;&lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:8" role="doc-endnote">
&lt;p>This works because most libraries use only the high-level &lt;code>threading&lt;/code> API to
handle their threads. A notable counter-example is &lt;a href="https://www.djangoproject.com/">Django&lt;/a>: I tried
getting Django to work before figuring out how &lt;code>_greenlet&lt;/code> could be
compiled, but Django imports the low-level &lt;code>_thread&lt;/code> API to handle things.&amp;#160;&lt;a href="#fnref:8" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:9" role="doc-endnote">
&lt;p>It is possible to have SSL support: you just have to build OpenSSL with
Cosmopolitan Libc. I was able to build &lt;code>libssl.a&lt;/code>, link it with &lt;code>python.com&lt;/code>
via &lt;code>Modules/Setup&lt;/code>, and &lt;code>pip&lt;/code> worked. However, I have not tested it with
the OpenSSL test suite.&amp;#160;&lt;a href="#fnref:9" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:10" role="doc-endnote">
&lt;p>The Cosmopolitan repo builds &lt;code>python.com&lt;/code> using &lt;a href="https://github.com/jart/cosmopolitan/blob/master/third_party/python/pyobj.c">&lt;code>PYOBJ.COM&lt;/code>&lt;/a>, a
minimal Python executable that creates &lt;code>.pyc&lt;/code> files and symbols for the
linker to resolve dependencies.&amp;#160;&lt;a href="#fnref:10" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Actually Portable Executables</title><link>https://ahgamut.github.io/2021/02/27/ape-cosmo/</link><pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate><guid>https://ahgamut.github.io/2021/02/27/ape-cosmo/</guid><description>&lt;p>I came across &lt;a href="https://github.com/jart/cosmopolitan">Cosmopolitan&lt;/a> on Hacker News, and I was initially
confused, due to a few memories of cross-compilation nightmares: while it should
be possible to compile for the same architecture regardless of operating system,
wouldn&amp;rsquo;t the OS get confused by the leading bytes of the executable? I read the
&lt;a href="https://justine.lol/ape.html">article&lt;/a> explaining how it works, but most of it went over my head.&lt;/p>
&lt;p>The example on the &lt;a href="https://github.com/jart/cosmopolitan">Github README&lt;/a> used the following script for
compilation:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">gcc -g -O -static -nostdlib -nostdinc -fno-pie -no-pie -mno-red-zone &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> -o hello.com.dbg hello.c -fuse-ld&lt;span class="o">=&lt;/span>bfd -Wl,-T,ape.lds &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> -include cosmopolitan.h crt.o ape.o cosmopolitan.a
objcopy -S -O binary hello.com.dbg hello.com
&lt;/code>&lt;/pre>&lt;/div>&lt;p>I converted it into a simple Makefile to run the compilation commands. I
tried a bunch of simple C programs (basic arithmetic, reading and writing to
files) on Linux+Windows (compiled on Linux), and all of them worked.&lt;/p>
&lt;h2 id="compiling-lua-with-cosmopolitan">Compiling Lua with Cosmopolitan&lt;/h2>
&lt;p>I decided to try compiling a high-level language built on C. I originally picked
Python, but the Makefile for Python seemed too complicated to mess with, so I
then picked &lt;a href="https://www.lua.org/download.html">Lua&lt;/a>, which looked much simpler in comparison.&lt;/p>
&lt;p>I started out by blindly copy-pasting the flags and includes used in the sample
compilation on Github. Ah, it would have been wonderful for my laziness if it
compiled out of the box. Following is a play-by-play commentary of trying to
compile Lua.&lt;/p>
&lt;p>First problem I ran into was header clashes: if I didn&amp;rsquo;t put &lt;code>-nostdlib -nostdinc&lt;/code> while compiling each object file, &lt;code>-include cosmopolitan.h&lt;/code> would
clash with the system headers. But blocking the system headers meant I would
have to change every &lt;code>#include&lt;/code> of a system header. I created a bunch of dummy
headers with the same names as those in the &lt;a href="https://en.cppreference.com/w/c/header">C stdlib&lt;/a> and and included
to those instead.&lt;/p>
&lt;p>Naming clashes: some of the macros in &lt;code>cosmopolitan.h&lt;/code> clashed with
macro/function names in Lua: &lt;code>reverse&lt;/code> and &lt;code>isempty&lt;/code>. I changed the Lua source
to avoid this.&lt;/p>
&lt;p>A macro &lt;code>FIRST_RESERVED&lt;/code> was broken because &lt;code>UCHAR_MAX&lt;/code> was missing. I
thought &lt;code>UCHAR_MAX&lt;/code> was supposed to be in &lt;code>limits.h&lt;/code> &amp;ndash; the &lt;code>limits.h&lt;/code> part of
&lt;code>cosmopolitan.h&lt;/code> did not have &lt;code>UCHAR_MAX&lt;/code> (It had &lt;code>SCHAR_MAX&lt;/code>, though.) I added
in a &lt;code>#define&lt;/code> stating &lt;code>UCHAR_MAX&lt;/code> as &lt;code>__UINT8_MAX__&lt;/code> (ie 255).&lt;/p>
&lt;p>The default Lua Makefile attempts to use &lt;code>_setjmp&lt;/code>/&lt;code>_longjmp&lt;/code> in &lt;code>ldo.c&lt;/code> when
on Linux. I disabled the &lt;code>LUA_USE_LINUX&lt;/code> flag for compiling the object files,
but this caused an issue with &lt;code>tmpnam&lt;/code> in &lt;code>loslib.c&lt;/code> (&lt;code>mkstemp&lt;/code> is available in
Cosmopolitan). I changed the Lua source to use &lt;code>setjmp&lt;/code>/&lt;code>longjmp&lt;/code>. A similar
issue showed in &lt;code>lauxlib.c&lt;/code> for &lt;code>sys/wait.h&lt;/code> (which is a no-op in non-POSIX
systems, as per the Lua source code), and in &lt;code>liolib&lt;/code> for &lt;code>sys/types.h&lt;/code> so
disabled &lt;code>LUA_USE_POSIX&lt;/code> over there as well.&lt;/p>
&lt;p>The &lt;code>localeconv()&lt;/code> function (part of &lt;code>locale.h&lt;/code>) was not implemented in
&lt;code>cosmopolitan.h&lt;/code>, and this caused an error while compiling &lt;code>lobject.c&lt;/code> (macro
&lt;code>lua_getlocaledecpoint()&lt;/code> depended on &lt;code>localeconv()&lt;/code>). Changed the macro to
just return &lt;code>'.'&lt;/code>.&lt;/p>
&lt;p>The &lt;code>panic&lt;/code> function in Lua &lt;code>static int panic (lua_state*)&lt;/code> clashed with that
in Cosmopolitan &lt;code>void panic(void)&lt;/code>. Renamed the lua function to &lt;code>lua_panic&lt;/code>.
This triggered an error where the &lt;code>panic&lt;/code> function was being called in
&lt;code>luaL_newstate&lt;/code>, so I changed the name there as well.&lt;/p>
&lt;p>&lt;code>luaL_loadfilex&lt;/code> caused a &lt;em>frame size error&lt;/em> &amp;ndash; I have never seen this before.
A quick internet search shows that this is because a large buffer is allocated
on stack when entering the function, and yes, &lt;code>luaL_loadfilex&lt;/code> allocates a
&lt;code>loadF&lt;/code> object containing a &lt;code>char&lt;/code> buffer of &lt;code>BUFSIZ&lt;/code>. I reduced the size of
the buffer to &lt;code>BUFSIZ - 64&lt;/code>.&lt;/p>
&lt;p>&lt;code>loslib.c&lt;/code> requires the &lt;code>setlocale()&lt;/code> and &lt;code>LC_*&lt;/code> from &lt;code>locale.h&lt;/code>, which is
defined as an extern value in &lt;code>cosmopolitan.h&lt;/code>, but that definition is somehow
not enough.. screw it, I just disabled &lt;code>os_setlocale&lt;/code> in &lt;code>loslib.c&lt;/code>, and then it
compiles.&lt;/p>
&lt;h2 id="linking-the-object-files">Linking the object files&lt;/h2>
&lt;p>Ok, time for linking &amp;hellip;&lt;/p>
&lt;pre tabindex="0">&lt;code>gcc -std=gnu99 -o lua lua.o liblua.a -lm -Wl,-E -ldl
/usr/bin/ld: errno: TLS definition in //lib/x86_64-linux-gnu/libc.so.6 section
.tbss mismatches non-TLS reference in liblua.a(lauxlib.o)
/usr/bin/ld: //lib/x86_64-linux-gnu/libc.so.6: error adding symbols: bad value
collect2: error: ld returned 1 exit status
&lt;/code>&lt;/pre>&lt;p>I forgot, I shouldn&amp;rsquo;t &lt;code>-lm&lt;/code> or &lt;code>-ldl&lt;/code>. Ok, let&amp;rsquo;s try with all the object files
instead of &lt;code>liblua.a&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>/usr/bin/ld.bfd: lvm.o: in function `l_strcmp':
lvm.c:(.text+0x59): undefined reference to `strcoll'
/usr/bin/ld.bfd: lmathlib.o: in function `math_tanh':
lmathlib.c:(.text+0x21f): undefined reference to `tanh'
/usr/bin/ld.bfd: lmathlib.o: in function `math_sinh':
lmathlib.c:(.text+0x24f): undefined reference to `sinh'
/usr/bin/ld.bfd: lmathlib.o: in function `math_cosh':
lmathlib.c:(.text+0x27f): undefined reference to `cosh'
collect2: error: ld returned 1 exit status
&lt;/code>&lt;/pre>&lt;p>Umm&amp;hellip; okay, it looks like some of the functions defined in the cosmopolitan
header are yet to be implemented in the static library. That&amp;rsquo;s okay, I can just
quickly fill in the math functions, and I&amp;rsquo;ll comment out &lt;code>strcoll&lt;/code> for now, just
because I want to see it compile&amp;hellip;. and it successfully compiles!! Let&amp;rsquo;s run
&lt;code>objcopy&lt;/code> before trying it out on a system though.&lt;/p>
&lt;pre tabindex="0">&lt;code>$ objcopy -S -O binary lua lua.exe
$ ls -al
-rwxr-xr-x 1 1953720 Feb 27 01:33 lua
-rwxr-xr-x 1 344064 Feb 27 01:39 lua.exe
&lt;/code>&lt;/pre>&lt;p>That size reduction seems a little too drastic, but let&amp;rsquo;s see if it runs on
Linux:&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/linux_screen.png" alt="">&lt;/p>
&lt;p>Awesome. How about Windows?&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/windows_screen.png" alt="">&lt;/p>
&lt;h2 id="summary-it-is-actually-portable">Summary: it &lt;em>is&lt;/em> actually portable&lt;/h2>
&lt;p>This is pretty incredible: I just had to modify a few lines in a Makefile and
some C source files, and I got a Lua executable that works both on Linux and
Windows (and possibly others as well). Granted, there are still some details to
be filled out (floating point calculation above prints a &lt;code>g&lt;/code>), but Cosmopolitan
is currently at release 0.2, so there is a lot of time. (&lt;strong>Update:&lt;/strong> Lua is
vendored as part of the Cosmopolitan repo since &lt;a href="https://github.com/jart/cosmopolitan/issues/61#issuecomment-792359199">March 8 2021&lt;/a>, and
is used for dynamic pages.)&lt;/p>
&lt;p>Hopefully this means that other languages that have source code completely in C
can also be compiled once and run anywhere. &lt;a href="https://ahgamut.github.io/2021/07/13/ape-python/">Actually Portable
Python&lt;/a> next, maybe?&lt;/p></description></item><item><title>Netpicking Part 2: Generating the networks</title><link>https://ahgamut.github.io/2020/11/24/netpicking-2/</link><pubDate>Tue, 24 Nov 2020 00:00:00 +0000</pubDate><guid>https://ahgamut.github.io/2020/11/24/netpicking-2/</guid><description>&lt;p>In &lt;a href="https://ahgamut.github.io/2020/11/20/netpicking-1/">Netpicking Part 1&lt;/a>, I described a dilemma in picking a neural network for MNIST. I went through
summary stats for 1001 different generated networks. This post explains how I generated these networks.&lt;/p>
&lt;h2 id="representing-a-neural-network">Representing a Neural Network&lt;/h2>
&lt;p>The MNIST problem requires finding a function&lt;/p>
&lt;p>$$ \mathit{f} : \R^{784} \rightarrow {0,1,2,3,4,5,6,7,8,9} $$&lt;/p>
&lt;p>such that $ \mathit{f} $ performs well on a target dataset. I can solve this as a &lt;strong>multi-class
classification problem&lt;/strong> using neural networks, and constrain the space of functions $ \mathit{f} $:&lt;/p>
&lt;ol>
&lt;li>Every $ \mathit{f} $ must accept an input of size &lt;code>784&lt;/code>&lt;/li>
&lt;li>Every $ \mathit{f} $ must provide an output of size &lt;code>10&lt;/code> for each input&lt;/li>
&lt;li>$ \mathit{f} $ is trained using cross-entropy loss i.e. the output goes through a &lt;code>SoftMax&lt;/code> layer&lt;/li>
&lt;/ol>
&lt;p>A neural network can be represented as:&lt;/p>
&lt;ul>
&lt;li>a parameterized function, used in textbooks when teaching the theory&lt;/li>
&lt;li>a &lt;em>directed acyclic graph&lt;/em> or DAG, which provides a visually friendly representation of the flow of
operations&lt;/li>
&lt;li>&lt;em>text obeying a particular grammar&lt;/em>, which is how neural nets are described in a programming language&lt;/li>
&lt;/ul>
&lt;p>For example, in PyTorch, a sample $ \mathit{f} $ satisfying the above constraints is represented like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">Basic&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">in_features&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">784&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="c1"># constraint 1&lt;/span>
&lt;span class="n">out_features&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="c1"># constraint 2&lt;/span>
&lt;span class="n">bias&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ac&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">LogSoftmax&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dim&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># constraint 3&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="c1"># DAG represented in text as function calls.&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ac&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>How about a sample using 2D convolutions?&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">Conv2dReLU_12&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f0&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">in_channels&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">out_channels&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">62&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">bias&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ReLU&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">in_channels&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">62&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">out_channels&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">),)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">in_channels&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">out_channels&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">bias&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f4&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ReLU&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f5&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">in_channels&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">out_channels&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">),)&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f6&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">LogSoftmax&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dim&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># constraint 3&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">view&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># constraint 1&lt;/span>
&lt;span class="c1"># DAG represented in function calls.&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f0&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f3&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f4&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f5&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">view&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># constraint 2&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f6&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now, a leap of faith generalization. Every function $ \mathit{f} $ that satisfies the above constraints
will follow the below template:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="k">class&lt;/span> &lt;span class="nc">Network&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span> &lt;span class="c1"># possibly some args, kwargs&lt;/span>
&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># a sequence of layer declarations&lt;/span>
&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">activation&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">LogSoftmax&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dim&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="c1"># check constraint 1&lt;/span>
&lt;span class="c1"># represent DAG in function calls&lt;/span>
&lt;span class="c1"># check constraint 2&lt;/span>
&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">activation&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># check constraint 3&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Having networks follow this template would save time when writing boilerplate code for train/validation/test
cycles. Let&amp;rsquo;s add another simplifying constraint: if the neural network DAG is forced to be a straight line,
the function calls in the &lt;code>forward&lt;/code> method can be in &lt;u>the same order&lt;/u> as the declarations. How do I
start designing such a template?&lt;/p>
&lt;h3 id="jinja2">&lt;code>Jinja2&lt;/code>&lt;/h3>
&lt;p>From the &lt;code>Jinja2&lt;/code> &lt;a href="https://jinja.palletsprojects.com/en/2.11.x/">website&lt;/a> (emphasis mine):&lt;/p>
&lt;blockquote>
&lt;p>Jinja is a modern and designer-friendly templating language for Python, modelled after Django&amp;rsquo;s templates.
[&amp;hellip;] A Jinja template is simply a text file. Jinja can generate &lt;em>any text-based format&lt;/em>.&lt;/p>
&lt;/blockquote>
&lt;p>Any text-based format, so the above Python code block also applies. The &lt;code>Jinja2&lt;/code> templating language provides
mathematical operators, logical operators, &lt;code>if-else&lt;/code>, and &lt;code>for&lt;/code> statements. If I create a template similar to
the &lt;code>Network&lt;/code> class above, &lt;del>instantiating&lt;/del>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> rendering that template with different parameters should
get the 1000 networks. Each network must have:&lt;/p>
&lt;ol>
&lt;li>(&lt;strong>Constraint 1&lt;/strong>): an &lt;code>input_shape&lt;/code> member, which can be used to shape the input.&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/li>
&lt;li>&lt;strong>a sequence of declarations&lt;/strong>. Naming the layers is simple (a loop with &lt;code>self.f1&lt;/code>, &lt;code>self.f2&lt;/code> &amp;hellip;),
but generating the layer declaration on the RHS seems complicated.&lt;/li>
&lt;li>&lt;strong>a sequence of function calls&lt;/strong> (the simplified DAG) in the &lt;code>forward&lt;/code> method. A loop with &lt;code>x = self.f{{ i }}(x)&lt;/code>.&lt;/li>
&lt;li>(&lt;strong>Constraint 2&lt;/strong>): its output shape cast to &lt;code>x,10&lt;/code> after the all the function calls.&lt;/li>
&lt;li>(&lt;strong>Constraint 3&lt;/strong>): a &lt;code>LogSoftmax&lt;/code> layer after the template declarations, and call it last.&lt;/li>
&lt;/ol>
&lt;p>Is declaring a layer really that complex? Let&amp;rsquo;s look at it again:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">f5&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">in_channels&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">out_channels&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">),)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Suppose I had an object &lt;code>x&lt;/code> of type &lt;code>Conv2d&lt;/code>, such that &lt;code>str(x)&lt;/code> returned &lt;code>&amp;quot;Conv2d(in_channels=22, out_channels=10)&amp;quot;&lt;/code>? Are there classes like this?&lt;/p>
&lt;p>The Python standard library provides &lt;a href="https://docs.python.org/3.6/library/collections.html#collections.namedtuple">&lt;code>collections.namedtuple&lt;/code>&lt;/a>, which has the right format for
stringified output. But then I need to write &lt;code>namedtuple&lt;/code> equivalents for so many classes! I wonder if there
is a way to examine (or inspect) the methods of a class to produce a &lt;code>namedtuple&lt;/code>.&lt;/p>
&lt;h3 id="inspect">&lt;code>inspect&lt;/code>&lt;/h3>
&lt;p>From the &lt;a href="https://docs.python.org/3.6/library/inspect.html">documentation&lt;/a>, the &lt;code>inspect&lt;/code> module in the Python standard library allows one to (emphasis
mine):&lt;/p>
&lt;blockquote>
&lt;p>[&amp;hellip;] get information about live objects such as modules, classes, methods, functions, tracebacks, frame
objects, and code objects [&amp;hellip;] &lt;em>examine the contents of a class&lt;/em>, retrieve the source code of a method,
&lt;em>extract and format the argument list for a function&lt;/em>, or get all the information needed to display a
detailed traceback.&lt;/p>
&lt;/blockquote>
&lt;p>For a class &lt;code>A&lt;/code>, I&amp;rsquo;d like to get a &lt;code>namedtuple&lt;/code> that has the same arguments and defaults as &lt;code>A.__init__&lt;/code> , so
that I can generate a string &lt;code>A(par1=val1, par2=val2)&lt;/code>. &lt;code>inspect&lt;/code> is perfect for this.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="kn">from&lt;/span> &lt;span class="nn">collections&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">namedtuple&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">inspect&lt;/span>
&lt;span class="k">def&lt;/span> &lt;span class="nf">get_namedtuple&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">obj&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="n">klass&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">obj&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">inspect&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">isclass&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">obj&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="nb">type&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">obj&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">sig&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">inspect&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">signature&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">klass&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">params&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">par&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">sig&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">name&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;self&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;*args&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;**kwargs&amp;#34;&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="k">continue&lt;/span>
&lt;span class="n">params&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="n">par&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">default&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="n">inspect&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Parameter&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">empty&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="n">param&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">par&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">default&lt;/span>
&lt;span class="n">tmpl_string&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">namedtuple&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">klass&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="vm">__name__&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">tuple&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">params&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keys&lt;/span>&lt;span class="p">()))&lt;/span>
&lt;span class="n">tmpl_string&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__new__&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="vm">__defaults__&lt;/span>&lt;span class="o">=&lt;/span> &lt;span class="nb">tuple&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">params&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">values&lt;/span>&lt;span class="p">()))&lt;/span>
&lt;span class="k">return&lt;/span> &lt;span class="n">tmpl_string&lt;/span>
&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">get_namedtuple&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ReLU&lt;/span>&lt;span class="p">)(&lt;/span>&lt;span class="n">inplace&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="c1"># ReLU(inplace=True)&lt;/span>
&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">get_namedtuple&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">)(&lt;/span>&lt;span class="n">in_features&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">out_features&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="c1"># Linear(in_features=2, out_features=3, bias=True)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Good enough; with the appropriate parameters, I can instantiate a &lt;code>namedtuple&lt;/code> that prints the exact layer
declaration I want.&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>&lt;/p>
&lt;h2 id="generating-the-1000-neural-networks">Generating the 1000 Neural Networks&lt;/h2>
&lt;p>Though &lt;a href="https://en.wikipedia.org/wiki/Automated_machine_learning">AutoML&lt;/a> has been around for &lt;a href="https://github.com/hibayesian/awesome-automl-papers">quite some time&lt;/a>, I didn&amp;rsquo;t want to generate networks for
this exercise with any optimization in mind. The aim was to have 1000 networks obeying the 4 constraints; I
decided to use random parameters while instantiating each layer.&lt;/p>
&lt;ul>
&lt;li>&lt;code>bool&lt;/code> parameters are &lt;code>True&lt;/code> with a probability in $ [0, 1] $.&lt;/li>
&lt;li>&lt;code>int&lt;/code>/&lt;code>float&lt;/code> parameters are randomly chosen from a given range with uniform probability.&lt;/li>
&lt;li>shape parameters like &lt;code>kernel_size&lt;/code> are square i.e. only one random &lt;code>int&lt;/code> selected.&lt;/li>
&lt;/ul>
&lt;p>Armed with the &lt;code>inspect&lt;/code>/&lt;code>Jinja2&lt;/code> combo, I wrote a &lt;a href="https://github.com/ahgamut/randonet/blob/master/driver.py">generation script&lt;/a> that would:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Select the number of layers in the network.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select a computation layer (&lt;code>Conv1d&lt;/code>, &lt;code>Conv2d&lt;/code>, &lt;code>Conv3d&lt;/code>, &lt;code>Linear&lt;/code>, or &lt;code>BasicBlock&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select an activation layer (None, &lt;code>ReLU&lt;/code>, &lt;code>SeLU&lt;/code>, &lt;code>Sigmoid&lt;/code>, &lt;code>Tanh&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Generate each layers of the network one by one with random parameters, using a &lt;code>namedtuple&lt;/code> template.&lt;/p>
&lt;ol>
&lt;li>Check that the generated layer can accept the input shape&lt;/li>
&lt;li>Precompute the output shape of the layer based on the input shape&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Ensure the generated network satisfies all constraints.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Repeat to generate 1000 networks across different kinds of computation/activation combinations.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The majority of debugging the script was in step 4: the input tensor would pass through a particular layer,
change shape, and would then be incompatible as input for the next layer. This was particularly annoying with
the inputs for ResNet &lt;code>BasicBlock&lt;/code> layers, which require an input of &lt;em>larger than&lt;/em> a particular size, which is
not obvious from the declaration.&lt;/p>
&lt;p>On the same note, look at the &lt;code>Conv2dReLU_12&lt;/code> code block again: Suppose it is known that the input is of shape &lt;code>(1, 1, 28, 28)&lt;/code>, and the DAG of the neural network is provided in text. It should be possible to tell what the
shape of the output is at any point in the DAG &lt;em>before&lt;/em> running the script to train/test the network. I know
the &lt;a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">&lt;code>Conv2d&lt;/code> documentation&lt;/a> includes the calculation of output shape from input shape, but having an IDE
plugin to provide the shapes would save a lot of time. Alternatively, type-checking the shapes before running
the network could help as well.&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>&lt;/p>
&lt;h2 id="closing-notes">Closing notes&lt;/h2>
&lt;p>&amp;ldquo;Dumb&amp;rdquo; AutoML can be realized by generating neural nets following a flexible template, followed to selecting
one with the &amp;ldquo;best&amp;rdquo; performance characteristics. The &lt;a href="https://github.com/ahgamut/randonet">&lt;code>randonet&lt;/code>&lt;/a> package (currently version 0.0.1)
contains the code involved to generate networks according to the ideas described above. I used it to generate
the networks for &lt;a href="https://github.com/ahgamut/mnistk">&lt;code>mnistk&lt;/code>&lt;/a> (you can see the difference between &lt;a href="https://github.com/ahgamut/mnistk/blob/master/src/mnistk/networks/conv1drelu_20.py">generated code&lt;/a> and the
&lt;a href="https://github.com/ahgamut/mnistk/blob/master/src/mnistk/run/trainer.py">handwritten code&lt;/a>).&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Writing neural network programs involves boilerplate/scaffolding code, which can be offset with some
templating (design patterns?) tailored to the specific problem at hand. I know wrapper packages exist, but
when I last tried them I got lost between the abstractions and my customizations.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;code>inspect&lt;/code>/&lt;code>Jinja2&lt;/code> combo has potential, especially for use cases involving the generation of contextual
information from objects/function in a package: it can possibly be used for generating documentation or
boilerplate code.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Randomly generating a valid neural net program involves a lot of constraints, some of which are not
apparent until the program is run. Removing some constraints would lead to wackier network architectures
(an unconstrained DAG instead of a line graph, rectangular/cuboidal convolutions).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Too much time around &lt;code>C++&lt;/code> templates and the mountain of errors I generate using them.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>I added another simplification here: &lt;code>Conv2d&lt;/code>/&lt;code>ResNetStyle&lt;/code> networks have an input of shape &lt;code>(N, 1, 28, 28)&lt;/code>, &lt;code>Conv1d&lt;/code> networks have &lt;code>(N, 28, 28)&lt;/code> (yes, 28 channels), &lt;code>Conv3d&lt;/code> networks have &lt;code>(N, 16, 7, 7)&lt;/code>, and
&lt;code>Linear&lt;/code> networks have &lt;code>(N, 784)&lt;/code>. I realized later that another layer of randomness could be added by
listing all 2-factor and 3-factor combinations of 784, but by then I had gotten bored of debugging
templated Python code.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Of course, there were too many classes in &lt;code>torch.nn&lt;/code> to call this function class by class, so I wrote
&lt;a href="https://github.com/ahgamut/randonet/blob/master/src/randonet/generator/factory_gen.py">another script&lt;/a> to generate the &lt;code>namedtuple&lt;/code>s corresponding to each class, instantiate
with the appropriate random values, and write the rendered templates to a file. Debugging that was
horrible: I had to typecheck the parameter defaults (PyTorch has an &lt;code>int&lt;/code> as default for &lt;code>kernel_size&lt;/code>
instead of a &lt;code>tuple&lt;/code>) generate the &lt;code>namedtuple&lt;/code>s, check if I could generate text using them in the
template, and &lt;em>then&lt;/em> check if the generated text was valid Python code.&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>Can the shape of input/output tensor be provided as a type annotation? How would that even work in Python?&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Netpicking Part 1: Hello MNIST</title><link>https://ahgamut.github.io/2020/11/20/netpicking-1/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>https://ahgamut.github.io/2020/11/20/netpicking-1/</guid><description>&lt;p>The &lt;code>Hello World!&lt;/code> introduction to neural network libraries has the user write a small network for the
&lt;a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST&lt;/a> dataset, train it, test it, get 90% accuracy or more, and thereby get a feel for how the
library works. When I started using &lt;a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html">PyTorch&lt;/a>, I followed such a tutorial on their website. But I
wondered why a network with &lt;code>Conv2d&lt;/code> and &lt;code>ReLU&lt;/code> was picked in the tutorial. Why not a different convolution or
a &lt;code>Linear&lt;/code> layer with a &lt;code>Sigmoid&lt;/code> activation?&lt;/p>
&lt;p>When someone designs a neural network, why do they pick a particular architecture? Obviously, some
conventions have set in, but the primary reason is performance: Network &lt;em>A&lt;/em> got a higher accuracy (or AUC)
than Network &lt;em>B&lt;/em>, so use &lt;em>A&lt;/em>. Is there more information I can use when making this decision? Let&amp;rsquo;s look at a
bunch of networks and find out.&lt;/p>
&lt;h2 id="measurements-and-baselines">Measurements and Baselines&lt;/h2>
&lt;p>Comparing a bunch of networks seems similar to a programming contest:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>A regular program&amp;rsquo;s&lt;/th>
&lt;th>is somewhat like a neural net&amp;rsquo;s&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Accuracy on test cases&lt;/td>
&lt;td>Accuracy on test set&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Compilation Time&lt;/td>
&lt;td>Training Time&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Binary size&lt;/td>
&lt;td>Number of parameters&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Memory usage&lt;/td>
&lt;td>Memory required to process a single input&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Algorithm Complexity&lt;/td>
&lt;td>number of &lt;code>ops&lt;/code> in the computation&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>I designed &lt;code>Basic&lt;/code>, a simple&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> model with bias as the baseline for the metrics. I trained it for &lt;code>4&lt;/code>
epochs, with the resulting performance:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>network&lt;/th>
&lt;th>weights&lt;/th>
&lt;th>memory usage&lt;/th>
&lt;th>training time&lt;/th>
&lt;th>number of ops&lt;/th>
&lt;th>accuracy&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>Basic&lt;/code>&lt;/td>
&lt;td>7850&lt;/td>
&lt;td>1588&lt;/td>
&lt;td>52.14s&lt;/td>
&lt;td>4&lt;/td>
&lt;td>0.912&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>The next step is design a bunch of &amp;ldquo;similar&amp;rdquo; networks and obtain their performance metrics.&lt;/p>
&lt;h2 id="getting-a-bunch-of-networks">Getting a bunch of networks&lt;/h2>
&lt;p>I quickly got bored writing different-yet-similar neural nets manually. &lt;a href="https://en.wiktionary.org/wiki/yak_shaving">Yak shaving&lt;/a> to the rescue! I
ended up &lt;a href="https://ahgamut.github.io/2020/11/24/netpicking-2/">generating&lt;/a> 1000 neural networks following a sequential template. The networks are classified
along two axes: computation layer, and activation layer. The networks are distributed as per the below table:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>↓ Computation / Activation →&lt;/th>
&lt;th>&lt;code>None&lt;/code>&lt;/th>
&lt;th>&lt;code>ReLU&lt;/code>&lt;/th>
&lt;th>&lt;code>SELU&lt;/code>&lt;/th>
&lt;th>&lt;code>Sigmoid&lt;/code>&lt;/th>
&lt;th>&lt;code>Tanh&lt;/code>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>Linear&lt;/code>&lt;/td>
&lt;td>55&lt;/td>
&lt;td>23&lt;/td>
&lt;td>24&lt;/td>
&lt;td>25&lt;/td>
&lt;td>23&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>Conv1d&lt;/code>&lt;/td>
&lt;td>59&lt;/td>
&lt;td>23&lt;/td>
&lt;td>24&lt;/td>
&lt;td>21&lt;/td>
&lt;td>23&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>Conv2d&lt;/code>&lt;/td>
&lt;td>61&lt;/td>
&lt;td>23&lt;/td>
&lt;td>23&lt;/td>
&lt;td>20&lt;/td>
&lt;td>23&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>Conv3d&lt;/code>&lt;/td>
&lt;td>57&lt;/td>
&lt;td>23&lt;/td>
&lt;td>23&lt;/td>
&lt;td>22&lt;/td>
&lt;td>25&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>Conv1dThenLinear&lt;/code>&lt;/td>
&lt;td>34&lt;/td>
&lt;td>17&lt;/td>
&lt;td>17&lt;/td>
&lt;td>17&lt;/td>
&lt;td>15&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>Conv2dThenLinear&lt;/code>&lt;/td>
&lt;td>38&lt;/td>
&lt;td>14&lt;/td>
&lt;td>16&lt;/td>
&lt;td>16&lt;/td>
&lt;td>16&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>Conv3dThenLinear&lt;/code>&lt;/td>
&lt;td>33&lt;/td>
&lt;td>18&lt;/td>
&lt;td>16&lt;/td>
&lt;td>18&lt;/td>
&lt;td>15&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>ResNetStyle&lt;/code>&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/td>
&lt;td>0&lt;/td>
&lt;td>100&lt;/td>
&lt;td>0&lt;/td>
&lt;td>0&lt;/td>
&lt;td>0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>For example, there are &lt;code>23&lt;/code> networks where the computation layer is &lt;code>Conv2d&lt;/code> and the activation layer is
&lt;code>ReLU&lt;/code>.&lt;/p>
&lt;p>So 1001 networks. Each trained for 4 epochs. The MNIST test set contains 10000 samples. A prediction of each
input has 10 scores. That gives a raw dataset of size &lt;code>(1001, 4, 10000, 10)&lt;/code>, and a summary dataset of size
&lt;code>(1001, 4, 20)&lt;/code>. Time to &lt;a href="https://www.youtube.com/watch?v=LPDn0PC6zFE">crunch the numbers!&lt;/a>&lt;/p>
&lt;h2 id="picking-the-best-network">Picking the &amp;ldquo;best&amp;rdquo; network&lt;/h2>
&lt;p>Let&amp;rsquo;s use the below analogy:&lt;/p>
&lt;blockquote>
&lt;p>There are 1000 students writing the MNIST exam. The exam has 10000 questions, multiple choice. The
students use approved study material, which contains 60000 practice questions. Each student has taken the
test 4 times. I have also written this exam, and I have a &lt;code>Basic&lt;/code> idea of what a good score is. I want to
hire one or more students who perform well on this exam.&lt;/p>
&lt;/blockquote>
&lt;p>The following ten are just some of the queries that can be posed:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>How did the students perform over 4 attempts?&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Attempt#&lt;/th>
&lt;th>≥ 80%&lt;/th>
&lt;th>≥ 90%&lt;/th>
&lt;th>≥ 95%&lt;/th>
&lt;th>≥ 99%&lt;/th>
&lt;th>≥ 100%&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>983&lt;/td>
&lt;td>792&lt;/td>
&lt;td>352&lt;/td>
&lt;td>0&lt;/td>
&lt;td>0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>990&lt;/td>
&lt;td>879&lt;/td>
&lt;td>461&lt;/td>
&lt;td>0&lt;/td>
&lt;td>0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>990&lt;/td>
&lt;td>907&lt;/td>
&lt;td>509&lt;/td>
&lt;td>0&lt;/td>
&lt;td>0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>4&lt;/td>
&lt;td>993&lt;/td>
&lt;td>924&lt;/td>
&lt;td>527&lt;/td>
&lt;td>5&lt;/td>
&lt;td>0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>So the exam was easy, but very few got close to a perfect score. Let&amp;rsquo;s just consider the &amp;ldquo;good&amp;rdquo; students:
those that got above 80% in all 4 test attempts. Of these, the &amp;ldquo;really good&amp;rdquo; students are those that got
above 98% in their last test attempts, and they get a gold star.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>I know the students studied together and developed common strategies. Which strategy led to more students
scoring high marks?&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/netpicking1/2.svg" alt="score1">&lt;/p>
&lt;p>Okay, &lt;code>ResNetStyle&lt;/code> is first&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup> (deeper networks better, skip connections are magic, blah blah), but
what about everyone else? Unsurprisingly, &lt;code>Conv2d&lt;/code> networks are second-best, but &lt;code>Conv3d&lt;/code> networks seem to
do an equally good job (lower maximum, but higher median and smaller spread). Adding &lt;code>Linear&lt;/code> layers after
convolution layers does not seem to be beneficial, perhaps the networks didn&amp;rsquo;t have enough training epochs.&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/netpicking1/2b.svg" alt="score2">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Argh! The move to consider networks without any activation was useless. Networks without
activations are just linear functions; combining each network&amp;rsquo;s weights would produce a matrix that is
effectively equal to the one used in &lt;code>Basic&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>As expected, networks that use the &lt;code>ReLU&lt;/code> activation have a higher accuracy on average than any of the
others.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Networks that use &lt;code>SELU&lt;/code> activation are not as good as those with &lt;code>ReLU&lt;/code>, but are more consistent.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>Sigmoid&lt;/code> and &lt;code>Tanh&lt;/code> activations are both risky choices.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>With the &lt;code>Basic&lt;/code> strategy, I spent only &lt;code>52&lt;/code> seconds studying for the test. How about the others?&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/netpicking1/3.svg" alt="time">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The &lt;code>Conv1d&lt;/code>, &lt;code>Linear&lt;/code>, and &lt;code>Conv1dThenLinear&lt;/code> networks take similar amounts of time to train. Does this
mean that the &lt;code>reshape&lt;/code> operation is slow? The other networks use 2D-convolutions or higher.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The gold stars are all across the board for &lt;code>ResNetStyle&lt;/code> networks, and generally on the higher end for the
others. However, the gold star in &lt;code>Conv3dThenLinear&lt;/code> takes the &lt;em>least&lt;/em> amount of training time in its
class; are &lt;code>Conv3d&lt;/code> networks slower to train?&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>With the &lt;code>Basic&lt;/code> strategy, I had only &lt;code>7850&lt;/code> keywords as part of my notes. How about the others?&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/netpicking1/4.svg" alt="params">&lt;/p>
&lt;p>Again, the gold stars are on the higher end of the distributions. This could imply deeper or wider networks
though.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>With the &lt;code>Basic&lt;/code> strategy, I used only &lt;code>1588&lt;/code> pages for rough work. How about the others?&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/netpicking1/5.svg" alt="mem">&lt;/p>
&lt;p>This plot is similar to the previous one. The memory required to hold the intermediate tensors is related
to the layers that output these tensors, examining the gold stars individually may give some information.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>With the &lt;code>Basic&lt;/code> strategy, I needed only &lt;code>4&lt;/code> steps to get an answer every time.
How about the others?&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/netpicking1/6.svg" alt="ops">&lt;/p>
&lt;p>Since all the networks are sequential, more operations means deeper networks. Now &amp;ldquo;deeper networks are
better&amp;rdquo; can be seen: the higher ends have the gold stars, but not all of them.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Every student took the test 4 times. How did the scores change over each attempt?&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/netpicking1/7.svg" alt="changes">&lt;/p>
&lt;p>This graph doesn&amp;rsquo;t tell much. It makes a case for early stopping: in most cases, the first two
epochs are sufficient to pick the best-trained network. There should be a better way to understand this
data; are there any networks that were horrible in the first two epochs, and then suddenly found a
wonderful local optimum?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>How many questions were easy, weird, or confusing?&lt;/p>
&lt;p>Out of the 10000 samples in the test set,&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>4247&lt;/strong> samples were easy questions. All the networks predicted these correctly, so it is impossible to
distinguish between the networks using any of these samples.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>8&lt;/strong> samples were weird questions. More than 90% of networks predicted these &lt;em>incorrectly&lt;/em>, but all of
them agreed got the &lt;em>same&lt;/em> incorrect answer.&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/netpicking1/8.svg" alt="weird">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>5&lt;/strong> samples were confusing questions. There was no clear agreement among the networks as to what the
answer was.&lt;/p>
&lt;p>&lt;img src="https://ahgamut.github.io/images/netpicking1/8b.svg" alt="confusing">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Let&amp;rsquo;s take the student with the best score. Is this person the &lt;em>best overall&lt;/em>?&lt;/p>
&lt;p>The network with the highest accuracy is &lt;code>ResNetStyle_75&lt;/code>, with an accuracy of 99.1%. To be the best
overall, it should have the highest accuracy for each class of inputs, so let&amp;rsquo;s look at the &lt;em>percentile&lt;/em>
of &lt;code>ResNetStyle_75&lt;/code> at predicting each digit correctly:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>name&lt;/th>
&lt;th>0&lt;/th>
&lt;th>1&lt;/th>
&lt;th>2&lt;/th>
&lt;th>3&lt;/th>
&lt;th>4&lt;/th>
&lt;th>5&lt;/th>
&lt;th>6&lt;/th>
&lt;th>7&lt;/th>
&lt;th>8&lt;/th>
&lt;th>9&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>ResNetStyle_75&lt;/code>&lt;/td>
&lt;td>99.19&lt;/td>
&lt;td>94.06&lt;/td>
&lt;td>98.59&lt;/td>
&lt;td>99.09&lt;/td>
&lt;td>90.33&lt;/td>
&lt;td>96.27&lt;/td>
&lt;td>96.68&lt;/td>
&lt;td>100.00&lt;/td>
&lt;td>94.56&lt;/td>
&lt;td>97.58&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>So there are some networks that are more accurate than &lt;code>ResNetStyle_75&lt;/code> at predicting individual classes.
&lt;code>ResNetStyle_75&lt;/code> has the worst percentile at predicting &lt;code>4&lt;/code>s correctly.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>How does the best student compare to the &lt;code>Basic&lt;/code> method?&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>network&lt;/th>
&lt;th>weights&lt;/th>
&lt;th>memory usage&lt;/th>
&lt;th>training time&lt;/th>
&lt;th>number of ops&lt;/th>
&lt;th>accuracy&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>ResNetStyle_75&lt;/code>&lt;/td>
&lt;td>531605&lt;/td>
&lt;td>254083&lt;/td>
&lt;td>577.6s&lt;/td>
&lt;td>28&lt;/td>
&lt;td>0.991&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>Basic&lt;/code>&lt;/td>
&lt;td>7850&lt;/td>
&lt;td>1588&lt;/td>
&lt;td>52.14s&lt;/td>
&lt;td>4&lt;/td>
&lt;td>0.912&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ratio&lt;/td>
&lt;td>67.7&lt;/td>
&lt;td>160&lt;/td>
&lt;td>11.07&lt;/td>
&lt;td>7.0&lt;/td>
&lt;td>1.08&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>For an 8% increase in accuracy, &lt;code>ResNetStyle_75&lt;/code> required 67x weights, 160x memory, and 11x training time.
How many members should an &lt;em>ensemble&lt;/em> of &lt;code>Basic&lt;/code> networks have to get a similar accuracy combined? 11? 67?
160?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="closing-notes">Closing Notes&lt;/h2>
&lt;p>Picking the best neural network, not surprisingly, depends on the definition of best (questions 3, 4, 5, and
6). Some use cases may value resource efficiency: a simple network with few parameters, that can be fast and
error-prone, would be easier to use in a constrained environment. Other cases may have heavy consequences
attached to a wrong prediction, and so will use a large, overparametrized network, located in a server with
multiple GPUs, to avoid error at all costs. Maybe the two extremes could work in tandem: the small network can
be provide a quick prediction, which can be checked by requesting the large network for a prediction if
needed.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Comparing a bunch of neural networks could also reveal some features about the dataset (question 8) that is
being used: if many networks are wrong for a given subset of the data, is the data labeled incorrectly?
Is the training set not large/representative enough of the underlying distribution? Do all the networks
suffer from a common issue?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Designing a bunch of neural networks may give an idea towards the importance of a particular design
(questions 1 and 2): do networks with similar designs get the same inputs wrong? It may also point to the
relative benefit of training a network for more epochs (question 7).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Designing a bunch of neural networks may also show the trade-offs involved in picking a particular network
(questions 9 and 10). Is an ensemble of shallow networks &amp;ldquo;better&amp;rdquo; than a single deep network?&lt;/p>
&lt;/li>
&lt;/ul>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>The network is just a &lt;code>784x10&lt;/code> matrix multiplication, adding a bias vector, and a &lt;code>Softmax&lt;/code> layer.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>The computation layer is a &lt;a href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py">ResNet &lt;code>BasicBlock&lt;/code>&lt;/a>.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>I realized after running all the networks that I could&amp;rsquo;ve modified the &lt;code>BasicBlock&lt;/code> to use different
activations instead of just &lt;code>ReLU&lt;/code>, which would&amp;rsquo;ve given a nice square matrix of subplots, and info about
how the &lt;code>BasicBlock&lt;/code> architecture is affected by different activations.&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item></channel></rss>